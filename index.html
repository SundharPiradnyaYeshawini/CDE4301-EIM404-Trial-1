<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url(https://themes.googleusercontent.com/fonts/css?kit=c6Fu_cJhJ2j2-ZxDMKauV6VXawJgyb8aFYJr-9wuJZM5KEqTDahEV1ECVSsZOMl9_kmCvy597kDopqFAXvpeaA);ul.lst-kix_krdfidlal6h-0{list-style-type:none}.lst-kix_j01k74qics3s-7>li:before{content:"\0025cb   "}ul.lst-kix_krdfidlal6h-1{list-style-type:none}ul.lst-kix_krdfidlal6h-2{list-style-type:none}.lst-kix_j01k74qics3s-6>li:before{content:"\0025cf   "}.lst-kix_j01k74qics3s-8>li:before{content:"\0025a0   "}ul.lst-kix_krdfidlal6h-3{list-style-type:none}.lst-kix_j01k74qics3s-3>li:before{content:"\0025cf   "}.lst-kix_j01k74qics3s-4>li:before{content:"\0025cb   "}.lst-kix_j01k74qics3s-5>li:before{content:"\0025a0   "}.lst-kix_j01k74qics3s-0>li:before{content:"\0025cf   "}ol.lst-kix_2amr3glbgc6g-2.start{counter-reset:lst-ctn-kix_2amr3glbgc6g-2 0}.lst-kix_dg4l5knv4qvi-6>li:before{content:"-  "}ul.lst-kix_krdfidlal6h-8{list-style-type:none}.lst-kix_dg4l5knv4qvi-4>li:before{content:"-  "}.lst-kix_dg4l5knv4qvi-5>li:before{content:"-  "}.lst-kix_j01k74qics3s-2>li:before{content:"\0025a0   "}.lst-kix_tqf6vkgmt3ou-3>li:before{content:"\0025cf   "}ul.lst-kix_krdfidlal6h-4{list-style-type:none}.lst-kix_j01k74qics3s-1>li:before{content:"" counter(lst-ctn-kix_j01k74qics3s-1,decimal) ". "}.lst-kix_dg4l5knv4qvi-3>li:before{content:"-  "}ul.lst-kix_krdfidlal6h-5{list-style-type:none}ul.lst-kix_krdfidlal6h-6{list-style-type:none}ul.lst-kix_krdfidlal6h-7{list-style-type:none}.lst-kix_tqf6vkgmt3ou-4>li:before{content:"\0025cb   "}.lst-kix_dg4l5knv4qvi-1>li:before{content:"-  "}ol.lst-kix_2amr3glbgc6g-8{list-style-type:none}ul.lst-kix_3jc2dorsi5zf-4{list-style-type:none}.lst-kix_3jc2dorsi5zf-6>li:before{content:"\0025cf   "}ul.lst-kix_3jc2dorsi5zf-3{list-style-type:none}ul.lst-kix_3jc2dorsi5zf-6{list-style-type:none}.lst-kix_3jc2dorsi5zf-7>li:before{content:"\0025cb   "}ul.lst-kix_3jc2dorsi5zf-5{list-style-type:none}.lst-kix_tqf6vkgmt3ou-5>li:before{content:"\0025a0   "}.lst-kix_tqf6vkgmt3ou-7>li:before{content:"\0025cb   "}ol.lst-kix_2amr3glbgc6g-4{list-style-type:none}ul.lst-kix_3jc2dorsi5zf-0{list-style-type:none}.lst-kix_3jc2dorsi5zf-8>li:before{content:"\0025a0   "}ol.lst-kix_2amr3glbgc6g-5{list-style-type:none}.lst-kix_dg4l5knv4qvi-2>li:before{content:"-  "}ol.lst-kix_2amr3glbgc6g-6{list-style-type:none}ul.lst-kix_3jc2dorsi5zf-2{list-style-type:none}ol.lst-kix_2amr3glbgc6g-7{list-style-type:none}ul.lst-kix_3jc2dorsi5zf-1{list-style-type:none}.lst-kix_vd42emnw8tkw-8>li:before{content:"\0025a0   "}.lst-kix_tqf6vkgmt3ou-6>li:before{content:"\0025cf   "}ul.lst-kix_dg4l5knv4qvi-6{list-style-type:none}ol.lst-kix_2amr3glbgc6g-0{list-style-type:none}.lst-kix_vd42emnw8tkw-6>li:before{content:"\0025cf   "}ul.lst-kix_dg4l5knv4qvi-7{list-style-type:none}ol.lst-kix_2amr3glbgc6g-1{list-style-type:none}ul.lst-kix_dg4l5knv4qvi-4{list-style-type:none}ol.lst-kix_2amr3glbgc6g-2{list-style-type:none}.lst-kix_vd42emnw8tkw-5>li:before{content:"\0025a0   "}ul.lst-kix_dg4l5knv4qvi-5{list-style-type:none}ol.lst-kix_2amr3glbgc6g-3{list-style-type:none}.lst-kix_vd42emnw8tkw-7>li:before{content:"\0025cb   "}ul.lst-kix_dg4l5knv4qvi-2{list-style-type:none}ul.lst-kix_dg4l5knv4qvi-3{list-style-type:none}.lst-kix_dg4l5knv4qvi-0>li:before{content:"-  "}ul.lst-kix_dg4l5knv4qvi-0{list-style-type:none}ul.lst-kix_dg4l5knv4qvi-1{list-style-type:none}.lst-kix_tqf6vkgmt3ou-8>li:before{content:"\0025a0   "}.lst-kix_vd42emnw8tkw-2>li:before{content:"\0025a0   "}.lst-kix_vd42emnw8tkw-1>li:before{content:"\0025cb   "}.lst-kix_vd42emnw8tkw-3>li:before{content:"\0025cf   "}.lst-kix_vd42emnw8tkw-0>li:before{content:"\0025cf   "}.lst-kix_vd42emnw8tkw-4>li:before{content:"\0025cb   "}ul.lst-kix_dg4l5knv4qvi-8{list-style-type:none}.lst-kix_2amr3glbgc6g-0>li{counter-increment:lst-ctn-kix_2amr3glbgc6g-0}ul.lst-kix_3jc2dorsi5zf-8{list-style-type:none}ul.lst-kix_3jc2dorsi5zf-7{list-style-type:none}ol.lst-kix_2amr3glbgc6g-8.start{counter-reset:lst-ctn-kix_2amr3glbgc6g-8 0}ul.lst-kix_hne5o7yp1po3-0{list-style-type:none}ul.lst-kix_vd42emnw8tkw-2{list-style-type:none}ul.lst-kix_vd42emnw8tkw-3{list-style-type:none}ul.lst-kix_vd42emnw8tkw-0{list-style-type:none}ul.lst-kix_vd42emnw8tkw-1{list-style-type:none}ul.lst-kix_vd42emnw8tkw-6{list-style-type:none}ul.lst-kix_hne5o7yp1po3-6{list-style-type:none}ul.lst-kix_vd42emnw8tkw-7{list-style-type:none}ul.lst-kix_hne5o7yp1po3-5{list-style-type:none}ul.lst-kix_vd42emnw8tkw-4{list-style-type:none}ul.lst-kix_hne5o7yp1po3-8{list-style-type:none}ul.lst-kix_vd42emnw8tkw-5{list-style-type:none}ul.lst-kix_hne5o7yp1po3-7{list-style-type:none}ul.lst-kix_hne5o7yp1po3-2{list-style-type:none}ul.lst-kix_hne5o7yp1po3-1{list-style-type:none}ul.lst-kix_vd42emnw8tkw-8{list-style-type:none}ul.lst-kix_hne5o7yp1po3-4{list-style-type:none}ul.lst-kix_hne5o7yp1po3-3{list-style-type:none}.lst-kix_2amr3glbgc6g-4>li{counter-increment:lst-ctn-kix_2amr3glbgc6g-4}.lst-kix_tqf6vkgmt3ou-2>li:before{content:"\0025a0   "}.lst-kix_tqf6vkgmt3ou-1>li:before{content:"\0025cb   "}.lst-kix_2amr3glbgc6g-7>li{counter-increment:lst-ctn-kix_2amr3glbgc6g-7}.lst-kix_tqf6vkgmt3ou-0>li:before{content:"\0025cf   "}ol.lst-kix_2amr3glbgc6g-3.start{counter-reset:lst-ctn-kix_2amr3glbgc6g-3 0}.lst-kix_2amr3glbgc6g-0>li:before{content:"" counter(lst-ctn-kix_2amr3glbgc6g-0,decimal) ". "}.lst-kix_dwiercyw12ae-8>li:before{content:"\0025a0   "}.lst-kix_dwiercyw12ae-6>li:before{content:"\0025cf   "}.lst-kix_2amr3glbgc6g-6>li:before{content:"" counter(lst-ctn-kix_2amr3glbgc6g-6,decimal) ". "}ul.lst-kix_j01k74qics3s-8{list-style-type:none}.lst-kix_2amr3glbgc6g-8>li:before{content:"" counter(lst-ctn-kix_2amr3glbgc6g-8,lower-roman) ". "}.lst-kix_dwiercyw12ae-0>li:before{content:"\0025cf   "}.lst-kix_dwiercyw12ae-2>li:before{content:"\0025a0   "}ul.lst-kix_j01k74qics3s-4{list-style-type:none}ul.lst-kix_j01k74qics3s-5{list-style-type:none}ul.lst-kix_j01k74qics3s-6{list-style-type:none}ul.lst-kix_j01k74qics3s-7{list-style-type:none}.lst-kix_2amr3glbgc6g-5>li{counter-increment:lst-ctn-kix_2amr3glbgc6g-5}ul.lst-kix_j01k74qics3s-0{list-style-type:none}ul.lst-kix_j01k74qics3s-2{list-style-type:none}ul.lst-kix_j01k74qics3s-3{list-style-type:none}.lst-kix_dwiercyw12ae-4>li:before{content:"\0025cb   "}.lst-kix_7c2l7ez6h3gu-6>li:before{content:"\0025cf   "}.lst-kix_x9xzz13qjok4-7>li:before{content:"\0025cb   "}.lst-kix_7c2l7ez6h3gu-4>li:before{content:"\0025cb   "}.lst-kix_hne5o7yp1po3-4>li:before{content:"\0025cb   "}.lst-kix_hne5o7yp1po3-8>li:before{content:"\0025a0   "}.lst-kix_x9xzz13qjok4-3>li:before{content:"\0025cf   "}.lst-kix_x9xzz13qjok4-5>li:before{content:"\0025a0   "}.lst-kix_7c2l7ez6h3gu-2>li:before{content:"\0025a0   "}.lst-kix_hne5o7yp1po3-2>li:before{content:"\0025a0   "}.lst-kix_krdfidlal6h-8>li:before{content:"\0025a0   "}.lst-kix_7c2l7ez6h3gu-0>li:before{content:"\0025cf   "}.lst-kix_2amr3glbgc6g-4>li:before{content:"" counter(lst-ctn-kix_2amr3glbgc6g-4,lower-latin) ". "}ol.lst-kix_2amr3glbgc6g-1.start{counter-reset:lst-ctn-kix_2amr3glbgc6g-1 0}.lst-kix_2amr3glbgc6g-6>li{counter-increment:lst-ctn-kix_2amr3glbgc6g-6}.lst-kix_2amr3glbgc6g-2>li:before{content:"" counter(lst-ctn-kix_2amr3glbgc6g-2,lower-roman) ". "}.lst-kix_x9xzz13qjok4-1>li:before{content:"\0025cb   "}.lst-kix_hne5o7yp1po3-6>li:before{content:"\0025cf   "}ul.lst-kix_x9xzz13qjok4-5{list-style-type:none}.lst-kix_g3v6ucj702wq-2>li:before{content:"\0025a0   "}ul.lst-kix_x9xzz13qjok4-6{list-style-type:none}ul.lst-kix_x9xzz13qjok4-3{list-style-type:none}ul.lst-kix_x9xzz13qjok4-4{list-style-type:none}ul.lst-kix_x9xzz13qjok4-7{list-style-type:none}ul.lst-kix_x9xzz13qjok4-8{list-style-type:none}ul.lst-kix_x9xzz13qjok4-1{list-style-type:none}.lst-kix_g3v6ucj702wq-4>li:before{content:"\0025cb   "}ul.lst-kix_x9xzz13qjok4-2{list-style-type:none}ul.lst-kix_x9xzz13qjok4-0{list-style-type:none}.lst-kix_hne5o7yp1po3-0>li:before{content:"\0025cf   "}.lst-kix_g3v6ucj702wq-0>li:before{content:"\0025cf   "}ol.lst-kix_2amr3glbgc6g-0.start{counter-reset:lst-ctn-kix_2amr3glbgc6g-0 0}.lst-kix_3jc2dorsi5zf-4>li:before{content:"\0025cb   "}.lst-kix_7c2l7ez6h3gu-8>li:before{content:"\0025a0   "}.lst-kix_3jc2dorsi5zf-2>li:before{content:"\0025a0   "}.lst-kix_dg4l5knv4qvi-7>li:before{content:"-  "}.lst-kix_3jc2dorsi5zf-0>li:before{content:"\0025cf   "}.lst-kix_g3v6ucj702wq-6>li:before{content:"\0025cf   "}.lst-kix_g3v6ucj702wq-8>li:before{content:"\0025a0   "}ol.lst-kix_2amr3glbgc6g-5.start{counter-reset:lst-ctn-kix_2amr3glbgc6g-5 0}.lst-kix_7lijgxczwod6-7>li:before{content:"\0025cb   "}.lst-kix_7lijgxczwod6-6>li:before{content:"\0025cf   "}.lst-kix_7lijgxczwod6-4>li:before{content:"\0025cb   "}.lst-kix_7lijgxczwod6-3>li:before{content:"\0025cf   "}.lst-kix_7lijgxczwod6-5>li:before{content:"\0025a0   "}.lst-kix_7lijgxczwod6-0>li:before{content:"\0025cf   "}.lst-kix_7lijgxczwod6-1>li:before{content:"\0025cb   "}.lst-kix_7lijgxczwod6-2>li:before{content:"\0025a0   "}.lst-kix_krdfidlal6h-2>li:before{content:"\0025a0   "}.lst-kix_krdfidlal6h-3>li:before{content:"\0025cf   "}.lst-kix_krdfidlal6h-0>li:before{content:"\0025cf   "}.lst-kix_krdfidlal6h-4>li:before{content:"\0025cb   "}ul.lst-kix_tqf6vkgmt3ou-1{list-style-type:none}.lst-kix_krdfidlal6h-6>li:before{content:"\0025cf   "}.lst-kix_krdfidlal6h-7>li:before{content:"\0025cb   "}ol.lst-kix_2amr3glbgc6g-4.start{counter-reset:lst-ctn-kix_2amr3glbgc6g-4 0}ul.lst-kix_tqf6vkgmt3ou-0{list-style-type:none}ul.lst-kix_tqf6vkgmt3ou-3{list-style-type:none}ul.lst-kix_tqf6vkgmt3ou-2{list-style-type:none}.lst-kix_krdfidlal6h-5>li:before{content:"\0025a0   "}ul.lst-kix_tqf6vkgmt3ou-8{list-style-type:none}ul.lst-kix_tqf6vkgmt3ou-5{list-style-type:none}ul.lst-kix_tqf6vkgmt3ou-4{list-style-type:none}.lst-kix_j01k74qics3s-1>li{counter-increment:lst-ctn-kix_j01k74qics3s-1}ul.lst-kix_tqf6vkgmt3ou-7{list-style-type:none}ul.lst-kix_tqf6vkgmt3ou-6{list-style-type:none}.lst-kix_7lijgxczwod6-8>li:before{content:"\0025a0   "}.lst-kix_krdfidlal6h-1>li:before{content:"\0025cb   "}.lst-kix_2amr3glbgc6g-1>li{counter-increment:lst-ctn-kix_2amr3glbgc6g-1}ol.lst-kix_j01k74qics3s-1.start{counter-reset:lst-ctn-kix_j01k74qics3s-1 0}.lst-kix_2amr3glbgc6g-1>li:before{content:"" counter(lst-ctn-kix_2amr3glbgc6g-1,lower-latin) ". "}ol.lst-kix_j01k74qics3s-1{list-style-type:none}.lst-kix_2amr3glbgc6g-5>li:before{content:"" counter(lst-ctn-kix_2amr3glbgc6g-5,lower-roman) ". "}.lst-kix_dwiercyw12ae-7>li:before{content:"\0025cb   "}.lst-kix_2amr3glbgc6g-7>li:before{content:"" counter(lst-ctn-kix_2amr3glbgc6g-7,lower-latin) ". "}.lst-kix_dwiercyw12ae-1>li:before{content:"\0025cb   "}.lst-kix_dwiercyw12ae-5>li:before{content:"\0025a0   "}.lst-kix_x9xzz13qjok4-8>li:before{content:"\0025a0   "}.lst-kix_dwiercyw12ae-3>li:before{content:"\0025cf   "}.lst-kix_7c2l7ez6h3gu-5>li:before{content:"\0025a0   "}.lst-kix_hne5o7yp1po3-3>li:before{content:"\0025cf   "}.lst-kix_hne5o7yp1po3-5>li:before{content:"\0025a0   "}.lst-kix_x9xzz13qjok4-6>li:before{content:"\0025cf   "}.lst-kix_7c2l7ez6h3gu-1>li:before{content:"\0025cb   "}.lst-kix_7c2l7ez6h3gu-3>li:before{content:"\0025cf   "}.lst-kix_hne5o7yp1po3-1>li:before{content:"\0025cb   "}ul.lst-kix_7c2l7ez6h3gu-8{list-style-type:none}.lst-kix_x9xzz13qjok4-4>li:before{content:"\0025cb   "}ul.lst-kix_7c2l7ez6h3gu-6{list-style-type:none}ul.lst-kix_7c2l7ez6h3gu-7{list-style-type:none}ul.lst-kix_7c2l7ez6h3gu-4{list-style-type:none}ul.lst-kix_7c2l7ez6h3gu-5{list-style-type:none}ul.lst-kix_7c2l7ez6h3gu-2{list-style-type:none}ul.lst-kix_7c2l7ez6h3gu-3{list-style-type:none}ul.lst-kix_7c2l7ez6h3gu-0{list-style-type:none}.lst-kix_x9xzz13qjok4-2>li:before{content:"\0025a0   "}ul.lst-kix_7c2l7ez6h3gu-1{list-style-type:none}.lst-kix_2amr3glbgc6g-3>li:before{content:"" counter(lst-ctn-kix_2amr3glbgc6g-3,decimal) ". "}.lst-kix_hne5o7yp1po3-7>li:before{content:"\0025cb   "}.lst-kix_x9xzz13qjok4-0>li:before{content:"\0025cf   "}.lst-kix_2amr3glbgc6g-3>li{counter-increment:lst-ctn-kix_2amr3glbgc6g-3}.lst-kix_g3v6ucj702wq-3>li:before{content:"\0025cf   "}.lst-kix_g3v6ucj702wq-1>li:before{content:"\0025cb   "}.lst-kix_g3v6ucj702wq-5>li:before{content:"\0025a0   "}ul.lst-kix_g3v6ucj702wq-0{list-style-type:none}ul.lst-kix_g3v6ucj702wq-1{list-style-type:none}.lst-kix_2amr3glbgc6g-2>li{counter-increment:lst-ctn-kix_2amr3glbgc6g-2}ul.lst-kix_g3v6ucj702wq-4{list-style-type:none}ul.lst-kix_g3v6ucj702wq-5{list-style-type:none}ul.lst-kix_g3v6ucj702wq-2{list-style-type:none}ul.lst-kix_g3v6ucj702wq-3{list-style-type:none}ol.lst-kix_2amr3glbgc6g-7.start{counter-reset:lst-ctn-kix_2amr3glbgc6g-7 0}ul.lst-kix_g3v6ucj702wq-8{list-style-type:none}ul.lst-kix_g3v6ucj702wq-6{list-style-type:none}.lst-kix_2amr3glbgc6g-8>li{counter-increment:lst-ctn-kix_2amr3glbgc6g-8}ul.lst-kix_g3v6ucj702wq-7{list-style-type:none}.lst-kix_3jc2dorsi5zf-5>li:before{content:"\0025a0   "}.lst-kix_7c2l7ez6h3gu-7>li:before{content:"\0025cb   "}ul.lst-kix_7lijgxczwod6-0{list-style-type:none}ul.lst-kix_dwiercyw12ae-7{list-style-type:none}ul.lst-kix_dwiercyw12ae-6{list-style-type:none}ul.lst-kix_dwiercyw12ae-8{list-style-type:none}ul.lst-kix_7lijgxczwod6-5{list-style-type:none}ul.lst-kix_dwiercyw12ae-3{list-style-type:none}ul.lst-kix_7lijgxczwod6-6{list-style-type:none}ul.lst-kix_dwiercyw12ae-2{list-style-type:none}.lst-kix_3jc2dorsi5zf-1>li:before{content:"\0025cb   "}.lst-kix_3jc2dorsi5zf-3>li:before{content:"\0025cf   "}ul.lst-kix_7lijgxczwod6-7{list-style-type:none}ul.lst-kix_dwiercyw12ae-5{list-style-type:none}ul.lst-kix_7lijgxczwod6-8{list-style-type:none}ul.lst-kix_dwiercyw12ae-4{list-style-type:none}ul.lst-kix_7lijgxczwod6-1{list-style-type:none}ul.lst-kix_7lijgxczwod6-2{list-style-type:none}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ul.lst-kix_7lijgxczwod6-3{list-style-type:none}ul.lst-kix_dwiercyw12ae-1{list-style-type:none}ul.lst-kix_7lijgxczwod6-4{list-style-type:none}ul.lst-kix_dwiercyw12ae-0{list-style-type:none}.lst-kix_dg4l5knv4qvi-8>li:before{content:"-  "}.lst-kix_g3v6ucj702wq-7>li:before{content:"\0025cb   "}ol.lst-kix_2amr3glbgc6g-6.start{counter-reset:lst-ctn-kix_2amr3glbgc6g-6 0}ol{margin:0;padding:0}table td,table th{padding:0}.c82{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#f3f3f3;border-left-style:solid;border-bottom-width:1pt;width:44.2pt;border-top-color:#000000;border-bottom-style:solid}.c72{border-right-style:solid;padding:7pt 7pt 7pt 7pt;border-bottom-color:#9e9e9e;border-top-width:1pt;border-right-width:1pt;border-left-color:#9e9e9e;vertical-align:top;border-right-color:#9e9e9e;border-left-width:1pt;border-top-style:solid;background-color:#ead1dc;border-left-style:solid;border-bottom-width:1pt;width:123.8pt;border-top-color:#9e9e9e;border-bottom-style:solid}.c38{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#d9d9d9;border-left-style:solid;border-bottom-width:1pt;width:114pt;border-top-color:#000000;border-bottom-style:solid}.c39{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:557.2pt;border-top-color:#000000;border-bottom-style:solid}.c0{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:225pt;border-top-color:#000000;border-bottom-style:solid}.c104{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:117.8pt;border-top-color:#000000;border-bottom-style:solid}.c89{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:111.8pt;border-top-color:#000000;border-bottom-style:solid}.c51{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:100.5pt;border-top-color:#000000;border-bottom-style:solid}.c65{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:259.5pt;border-top-color:#000000;border-bottom-style:solid}.c20{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:286.5pt;border-top-color:#000000;border-bottom-style:solid}.c81{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:93.8pt;border-top-color:#000000;border-bottom-style:solid}.c92{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:114pt;border-top-color:#000000;border-bottom-style:solid}.c58{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:270.8pt;border-top-color:#000000;border-bottom-style:solid}.c80{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:107.2pt;border-top-color:#000000;border-bottom-style:solid}.c77{border-right-style:solid;padding:7pt 7pt 7pt 7pt;border-bottom-color:#9e9e9e;border-top-width:1pt;border-right-width:1pt;border-left-color:#9e9e9e;vertical-align:top;border-right-color:#9e9e9e;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:123.8pt;border-top-color:#9e9e9e;border-bottom-style:solid}.c40{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:225.7pt;border-top-color:#000000;border-bottom-style:solid}.c98{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:81pt;border-top-color:#000000;border-bottom-style:solid}.c53{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:90pt;border-top-color:#000000;border-bottom-style:solid}.c87{border-right-style:solid;padding:7pt 7pt 7pt 7pt;border-bottom-color:#9e9e9e;border-top-width:1pt;border-right-width:1pt;border-left-color:#9e9e9e;vertical-align:top;border-right-color:#9e9e9e;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:114.8pt;border-top-color:#9e9e9e;border-bottom-style:solid}.c25{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:112.5pt;border-top-color:#000000;border-bottom-style:solid}.c88{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:451.4pt;border-top-color:#000000;border-bottom-style:solid}.c15{-webkit-text-decoration-skip:none;color:#000000;font-weight:700;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:12pt;font-family:"Arial";font-style:normal}.c29{background-color:#ffffff;color:#212121;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c5{background-color:#ffffff;color:#212121;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:italic}.c12{color:#0b57d0;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c9{color:#0000ff;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c52{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:justify}.c36{margin-left:-4pt;padding-top:0pt;padding-bottom:0pt;line-height:1.4285714285714286;orphans:2;widows:2;text-align:left}.c43{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:justify}.c14{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:italic}.c8{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:justify;height:11pt}.c48{padding-top:12pt;padding-bottom:2pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c78{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;text-align:left;height:20pt}.c31{color:#041834;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial"}.c4{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c54{padding-top:18pt;padding-bottom:6pt;line-height:1.0;page-break-after:avoid;text-align:left;height:16pt}.c27{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c13{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c50{padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c55{font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Roboto";font-style:normal}.c21{margin-left:288pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:center}.c86{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;text-align:center}.c103{padding-top:18pt;padding-bottom:6pt;line-height:1.0;page-break-after:avoid;text-align:left}.c102{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;text-align:left}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left;height:11pt}.c85{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;text-align:left}.c96{padding-top:16pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;text-align:justify}.c127{padding-top:18pt;padding-bottom:6pt;line-height:1.0;page-break-after:avoid;text-align:justify}.c18{text-decoration-skip-ink:none;font-size:11pt;-webkit-text-decoration-skip:none;font-weight:700;text-decoration:underline}.c109{background-color:#ffffff;padding-top:20pt;padding-bottom:4pt;line-height:1.15;text-align:left}.c61{padding-top:3pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c68{padding-top:12pt;padding-bottom:12pt;line-height:1.0;text-align:justify}.c19{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c100{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c33{margin-left:-39pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c126{font-weight:900;vertical-align:baseline;font-family:"Raleway";font-style:normal}.c3{padding-top:12pt;padding-bottom:12pt;line-height:1.15;text-align:justify}.c70{margin-left:-59.2pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c22{color:#000000;vertical-align:baseline;font-family:"Arial";font-style:italic}.c34{margin-left:auto;border-spacing:0;border-collapse:collapse;margin-right:auto}.c73{padding-top:12pt;padding-bottom:12pt;line-height:1.0;text-align:left}.c26{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:center}.c49{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c16{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c23{color:#000000;vertical-align:baseline;font-family:"Arial";font-style:normal}.c121{margin-left:103.8pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c108{margin-left:-50.2pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c28{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:justify}.c62{font-weight:400;vertical-align:baseline;font-family:"Arial";font-style:normal}.c94{border-spacing:0;border-collapse:collapse;margin-right:auto}.c59{padding-top:12pt;padding-bottom:2pt;line-height:1.15;text-align:center}.c47{font-weight:400;text-decoration:none;font-size:9pt}.c66{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;text-decoration:underline}.c90{vertical-align:baseline;font-family:"Arial";font-style:normal}.c105{font-size:12pt;font-family:"Roboto";font-weight:400}.c64{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;text-decoration:underline line-through}.c111{-webkit-text-decoration-skip:none;text-decoration:line-through;text-decoration-skip-ink:none}.c130{vertical-align:baseline;font-family:"Open Sans";font-style:normal}.c97{font-weight:400;text-decoration:none;font-size:20pt}.c79{font-weight:400;text-decoration:none;font-size:14pt}.c75{text-decoration:none;font-size:12pt}.c44{text-decoration:none;font-size:11pt}.c95{text-decoration:none;font-size:18pt}.c30{margin-left:72pt;padding-left:0pt}.c42{background-color:#ffffff;color:#0000ff}.c37{padding:0;margin:0}.c107{text-decoration:none;font-size:8pt}.c76{background-color:#ffffff;color:#212121}.c113{text-decoration:none;font-size:14pt}.c123{max-width:451.4pt;padding:72pt 72pt 72pt 72pt}.c114{vertical-align:baseline;font-family:"Arial"}.c57{orphans:2;widows:2}.c17{margin-left:36pt;padding-left:0pt}.c7{border:1px solid black;margin:5px}.c6{color:inherit;text-decoration:inherit}.c99{font-size:18pt;font-family:"Roboto"}.c115{background-color:#d5a6bd}.c118{text-decoration:none}.c67{color:#191919}.c101{background-color:#d9d9d9}.c106{font-weight:400}.c45{color:#444746}.c122{color:#1155cc}.c119{height:26pt}.c24{font-style:italic}.c124{height:214pt}.c84{height:31pt}.c46{margin-left:36pt}.c10{height:0pt}.c129{height:47.7pt}.c11{height:11pt}.c56{vertical-align:super}.c112{height:34.5pt}.c120{height:8.2pt}.c74{font-size:9pt}.c83{color:#041834}.c117{font-size:16pt}.c71{background-color:#b6d7a8}.c35{color:#0b57d0}.c110{background-color:#ffffff}.c116{text-indent:36pt}.c41{background-color:#ffff00}.c69{font-size:11pt}.c125{height:20pt}.c32{font-weight:700}.c91{background-color:#ead1dc}.c60{height:39.1pt}.c128{background-color:#f1c232}.c63{margin-left:18pt}.c93{vertical-align:sub}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c110 c123 doc-content"><h1 class="c78 c57" id="h.1cvhsvtfw6e3"><span class="c23 c32 c95"></span></h1><h1 class="c57 c86" id="h.bju35k4ans1w"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 399.64px; height: 248.03px;"><img alt="" src="images/image26.png" style="width: 399.64px; height: 248.03px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></h1><p class="c26"><span class="c67 c32 c99">Wearable Digital Sensors for Early Detection of Mild Cognitive Impairment</span></p><h1 class="c86 c57 c125" id="h.d4jlec7zs9eu"><span class="c23 c97"></span></h1><p class="c4 c11"><span class="c23 c113 c32"></span></p><table class="c34"><tr class="c10"><td class="c40 c101" colspan="1" rowspan="1"><p class="c26"><span class="c23 c113 c32">Name </span></p></td><td class="c40 c101" colspan="1" rowspan="1"><p class="c26"><span class="c23 c32 c113">Matric Number </span></p></td></tr><tr class="c10"><td class="c40" colspan="1" rowspan="1"><p class="c26"><span class="c23 c79">Amanda Goh</span></p></td><td class="c40" colspan="1" rowspan="1"><p class="c26"><span class="c23 c79">A0277481U</span></p></td></tr><tr class="c10"><td class="c40" colspan="1" rowspan="1"><p class="c100"><span class="c23 c79">Kelvyna Lee En</span></p></td><td class="c40" colspan="1" rowspan="1"><p class="c100"><span class="c23 c79">A0257628R</span></p></td></tr><tr class="c10"><td class="c40" colspan="1" rowspan="1"><p class="c100"><span class="c23 c79">Sundhar Piradnya Yeshawini </span></p></td><td class="c40" colspan="1" rowspan="1"><p class="c100"><span class="c23 c79">A0266687H</span></p></td></tr></table><p class="c28 c57 c11"><span class="c2"></span></p><p class="c100 c11"><span class="c118 c106 c83 c117 c130"></span></p><h1 class="c78 c57" id="h.w5lf1phwbbnu"><span class="c15"></span></h1><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c27"><span class="c18 c23">CONTENT PAGE</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c61"><span class="c32"><a class="c6" href="#h.nojg9no83qpy">1. Introduction&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10</a></span></p><p class="c61 c63"><span><a class="c6" href="#h.ntqsahsbq8ts">1.1) Background Information&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10</a></span></p><p class="c61 c63"><span><a class="c6" href="#h.x47gw3z6yosn">1.2) Project Overview&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10</a></span></p><p class="c61 c46"><span><a class="c6" href="#h.4p7tkyylgvy2">1.2.1) Prof Wu&rsquo;s sensor and current project status&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10</a></span></p><p class="c61 c46"><span><a class="c6" href="#h.78ydkntz6ud8">1.2.2) Devices&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;11</a></span></p><p class="c61 c63"><span><a class="c6" href="#h.c5cjbxkwuy08">1.3) Project Specifications&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;12</a></span></p><p class="c61 c63"><span><a class="c6" href="#h.nsliuptslhwp">1.4) Project Scope&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;12</a></span></p><p class="c61"><span class="c32"><a class="c6" href="#h.z0l6ao8ts54h">2. Gait&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;12</a></span></p><p class="c61 c63"><span>Literature review (Gait)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;12</span></p><p class="c61"><span class="c32"><a class="c6" href="#h.vsuye0dy77c">3. Speech&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;13</a></span></p><p class="c61 c63"><span><a class="c6" href="#h.sopk3cnsm0xz">Speech analysis (200Hz)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;13</a></span></p><h1 class="c57 c78" id="h.2jfk0ca2atma"><span class="c15"></span></h1><h1 class="c78 c57" id="h.cg7mzeug78hf"><span class="c15"></span></h1><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><ol class="c37 lst-kix_2amr3glbgc6g-0 start" start="1"><li class="c57 c17 c102 li-bullet-0"><h1 id="h.nojg9no83qpy" style="display:inline"><span class="c15">Introduction</span></h1></li></ol><h2 class="c85 c57" id="h.k9d7crm9dv0"><span class="c18 c23">Pre-intro:</span></h2><ul class="c37 lst-kix_krdfidlal6h-0 start"><li class="c4 c17 li-bullet-0"><span class="c2">Group project</span></li><li class="c4 c17 li-bullet-0"><span class="c2">Who specialized/ focused on/ headed each section</span></li></ul><ul class="c37 lst-kix_krdfidlal6h-1 start"><li class="c4 c30 li-bullet-0"><span class="c2">Kel</span></li><li class="c4 c30 li-bullet-0"><span class="c2">Amanda</span></li><li class="c4 c30 li-bullet-0"><span class="c2">Piradnya &nbsp;- Gait Data collection, Prototype &amp; Analysis; Speech Testing &amp; Data Analysis</span></li><li class="c4 c30 li-bullet-0"><span class="c2">All - Literature reviews, sensor strap, evaluation of speech, (+add on others you can think of)</span></li></ul><h2 class="c57 c85" id="h.ntqsahsbq8ts"><span class="c18 c23">1.1) Context/ Motivation</span></h2><p class="c13"><span class="c2">(Project context)</span></p><p class="c13"><span>This project is conducted in collaboration with Professor Wu Changsheng&rsquo;s laboratory, which partners with clinicians and students from the Saw Swee Hock School Of Public Health. This project is part of an ongoing study on developing a tool to detect for MCI biomarkers in patients. The overarching goal of the collaborative project is to develop an advanced, non-invasive wireless wearable mechano-acoustic sensor system to monitor vocal attributes and gait patterns for the early detection of </span><span>MCI.</span><sup><a href="#cmnt1" id="cmnt_ref1">[a]</a></sup><span>&nbsp;</span></p><p class="c8"><span class="c2"></span></p><p class="c13"><span>[block diagram] </span><sup><a href="#cmnt2" id="cmnt_ref2">[b]</a></sup></p><p class="c8"><span class="c2 c71"></span></p><p class="c13"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 365.05px;"><img alt="" src="images/image17.png" style="width: 601.70px; height: 365.05px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c8"><span class="c2 c71"></span></p><p class="c8"><span class="c2 c71"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c13"><span>A</span><span>s such, the problem statement of the collaborative research project is:</span><span class="c32">&nbsp;&ldquo;How might we make the detection of Mild Cognitive Impairment more timely, affordable, and non-invasive?&rdquo;</span><sup><a href="#cmnt3" id="cmnt_ref3">[c]</a></sup><sup><a href="#cmnt4" id="cmnt_ref4">[d]</a></sup><span class="c23 c44 c32">&nbsp;</span></p><p class="c13"><span class="c32">(big big HMW)</span></p><p class="c13"><span class="c2">&nbsp;</span></p><p class="c8"><span class="c2"></span></p><p class="c13"><span class="c2">(MCI background)</span></p><p class="c13"><span>Mild Cognitive Impairment (MCI) is widely recognised as an intermediate stage between normal age-related cognitive decline and dementia. [</span><span class="c41">cite</span><span>] It is characterised by noticeable deficits in memory, attention, and judgment that are greater than expected for a person&rsquo;s age, yet not severe enough to significantly interfere with daily activities [</span><span class="c41">cite</span><span class="c2">]. Individuals with MCI are able to carry out daily activities, but may experience increasing difficulty in performing complex tasks.</span></p><p class="c8"><span class="c2"></span></p><p class="c13"><span>MCI is a critical focus area for research because it represents a potential window for early intervention before irreversible neurodegeneration occurs. While some individuals may recover normal cognitive function, numerous longitudinal studies have shown that people with MCI are at a significantly higher risk of progressing to dementia or Alzheimer&rsquo;s disease (</span><span class="c41">Petersen et al., 2018; Jongsiriyanyong &amp; Limpawattana, 2018</span><span class="c2">).</span></p><p class="c8"><span class="c2"></span></p><p class="c13"><span>In Singapore, approximately 12.5% of adults aged 60 and above are estimated to have MCI </span><span class="c41">(Subramaniam et al., 2015)</span><span>. With the country&rsquo;s rapidly ageing population, this prevalence and its associated healthcare burden is expected to increase. The Ministry of Health (MOH) projects that by 2030, as many as 152,000 people could be living with dementia, incurring an additional S$106 million in annual healthcare expenditure. The median annual cost of care for MCI patients is approximately S$13,800, including medical consultations, imaging scans, and long-term management. </span><span class="c2 c41">[cite]</span></p><p class="c4 c11"><span class="c18 c23"></span></p><p class="c4"><span class="c66 c115 c32">[Point 2: Lit review for </span><span class="c66 c115 c32">MCI </span><sup><a href="#cmnt5" id="cmnt_ref5">[e]</a></sup><span class="c18 c23 c115">devices]</span></p><p class="c13"><span class="c2">The growing prevalence of MCI and dementia highlights the urgent need for early, accessible, and cost-effective detection methods. </span></p><p class="c8"><span class="c2"></span></p><p class="c13"><span class="c2">Current screening and diagnostic procedures include Magnetic Resonance Imaging (MRI) or Positron Emission Tomography (PET) brain scans, neuropsychological testing, and biochemical analysis of cerebrospinal fluids. While these are definitive and accurate, they are expensive, invasive, and resource-intensive. These hinder widespread adoption of screening for MCI, especially for early or community-based screening. Additionally, such assessments are typically performed only after cognitive symptoms become clinically apparent. Early diagnosis remains a challenge, as subtle physiological and behavioural changes frequently go unnoticed in routine clinical visits.</span></p><p class="c8"><span class="c2"></span></p><p class="c13"><span class="c2">Given these challenges, there is a need to develop a non-invasive, scalable, and affordable tool that can continuously monitor subtle indicators of cognitive decline. </span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span class="c66 c32">Kel</span><sup><a href="#cmnt6" id="cmnt_ref6">[f]</a></sup></p><p class="c4 c11"><span class="c18 c23"></span></p><p class="c4"><span class="c32 c64">1.1.2 ) </span><span class="c64 c32">Problem </span><span class="c64 c32">statement </span><sup><a href="#cmnt7" id="cmnt_ref7">[g]</a></sup></p><p class="c4"><span class="c18 c23">[project specs]</span></p><ul class="c37 lst-kix_hne5o7yp1po3-0 start"><li class="c4 c17 li-bullet-0"><span class="c2">Big project specs</span></li><li class="c4 c17 li-bullet-0"><span class="c2">Gait project specs (accelerometer data) &ndash; because the device only uses accelerometer</span></li><li class="c4 c17 li-bullet-0"><span class="c2">Speech specs &ndash; non-invasive (privacy) etc</span></li></ul><h2 class="c85 c57" id="h.84ehibx0n8f0"><span class="c69">Device </span><span class="c69">Specifications </span><sup><a href="#cmnt8" id="cmnt_ref8">[h]</a></sup></h2><table class="c94"><tr class="c119"><td class="c88" colspan="2" rowspan="1"><p class="c19"><span class="c2">Design Requirement </span></p></td></tr><tr class="c119"><td class="c88" colspan="2" rowspan="1"><p class="c19"><span class="c2">The proposed system is designed to be wearable , comfortable and practical for daily use by older adults and clinics.It will be small ,lightweight and waterproof to ensure comfort. It operates non inversely, capturing motion and vocal signals without wires or cameras , and it is easy to use for both users and caregivers, The device is also reliable and secure, with stable performance , long battery life and protected data handling.</span></p></td></tr></table><p class="c1"><span class="c18 c23"></span></p><h2 class="c85 c57" id="h.x47gw3z6yosn"><span class="c64 c69 c32">1.2) </span><span class="c64 c32 c69">Project </span><sup><a href="#cmnt9" id="cmnt_ref9">[i]</a></sup><sup><a href="#cmnt10" id="cmnt_ref10">[j]</a></sup><span class="c23 c64 c69 c32">Outline</span></h2><p class="c4"><span class="c18 c23">[pt 4: objectives] </span></p><ul class="c37 lst-kix_dwiercyw12ae-0 start"><li class="c13 c17 li-bullet-0"><span>OUR project objectives (how might wes)</span><sup><a href="#cmnt11" id="cmnt_ref11">[k]</a></sup></li></ul><p class="c8"><span class="c2"></span></p><p class="c13"><span class="c23 c44 c32">[pt 5: scope]</span></p><ul class="c37 lst-kix_tqf6vkgmt3ou-0 start"><li class="c13 c17 li-bullet-0"><span>Further elab on objectives (what we do) vs in context of big project</span></li></ul><sup><a href="#cmnt12" id="cmnt_ref12">[l]</a></sup><p class="c8"><span class="c2"></span></p><h2 class="c52" id="h.nsliuptslhwp"><span class="c18 c23">1.4) Project Scope </span></h2><h1 class="c43" id="h.ilp3djog6nj"><span class="c23 c66 c106 c69">IDP Students Project Scope</span></h1><h1 class="c43" id="h.d5i599j5a4u"><span class="c69">There are two parts that we will be focusing on: Gait and Speech. For gait, we are to</span><span class="c69 c32">&nbsp;extract </span><span class="c69">and</span><span class="c69 c32">&nbsp;validate gait features </span><span class="c69">that differ between healthy and MCI individuals, while for Speech, our goal is to </span><span class="c69 c32">capture</span><span class="c69">&nbsp;and</span><span class="c69 c32">&nbsp;analyse</span><span class="c69">&nbsp;vibration-based speech signals to identify early vocal markers of MCI. </span></h1><h1 class="c43" id="h.e9ld4ekivlys"><span class="c23 c66 c106 c69">Prof Wu&rsquo;s Project Scope</span></h1><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span>Prof Wu&rsquo;s scope covers the hardware( sensor design), software (data processing), and clinical application aspects of wearable mechanical-acoustic sensing systems for cognitive and physiological monitoring </span></p><h3 class="c57 c46 c96" id="h.4p7tkyylgvy2"><span class="c18 c23">Prof Wu&rsquo;s sensor and current project status </span></h3><p class="c3 c46 c57"><span class="c2">Prof Wu&rsquo;s lab developed a custom mechano-acoustic wearable sensor designed to capture vibration and motion signals from the throat and lower limb. The sensor integrates a three-axis accelerometer within a silicone encapsulation, making it lightweight, waterproof, and comfortable for continuous use. During earlier testing, the lab deployed this device on over 200 patients during the COVID-19 period, proving its robustness for physiological monitoring and speech tracking. </span></p><p class="c3 c57 c46"><span>The </span><span class="c32">NUS team</span><span class="c2">&nbsp;has since worked on:</span></p><ul class="c37 lst-kix_3jc2dorsi5zf-0 start"><li class="c68 c30 c57 li-bullet-0"><span class="c2">Encapsulation improvements to protect the electronics and maintain skin comfort.<br></span></li><li class="c68 c30 c57 li-bullet-0"><span class="c2">Adhesive and strap design testing for better attachment during movement or sweating.<br></span></li><li class="c68 c30 c57 li-bullet-0"><span>Firmware updates to enable onboard data storage and Bluetooth communication.<br></span><span class="c18 c23">1.2.2) Devices </span></li></ul><p class="c50"><span class="c18 c23">Three sensor options exist:</span></p><ol class="c37 lst-kix_j01k74qics3s-1 start" start="1"><li class="c50 c30 li-bullet-0"><span class="c2">MetaBase (commercial) &ndash; reliable but needs daily charging and participant app use.</span></li><li class="c50 c30 li-bullet-0"><span class="c2">Silicone in-house sensor (Research sensor) &ndash; simpler for patients, records automatically, 4&ndash;5 day battery life.</span></li><li class="c50 c30 li-bullet-0"><span class="c2">Vicon (Motion sensor) - Our gold standard and is used to compare with the Metabase sesnor for gait </span></li></ol><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 579.50px; height: 324.62px;"><img alt="" src="images/image7.png" style="width: 579.50px; height: 324.62px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c11"><span class="c18 c23"></span></p><p class="c4 c116"><span class="c32">(</span><span class="c32">Patient Journey</span><sup><a href="#cmnt13" id="cmnt_ref13">[m]</a></sup><span class="c23 c44 c32">&nbsp;)- How are we going to integrate the research sensor </span></p><p class="c4 c11"><span class="c18 c23 c41"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 534.69px; height: 362.31px;"><img alt="" src="images/image3.png" style="width: 534.69px; height: 362.31px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h1 class="c102 c57" id="h.z0l6ao8ts54h"><span class="c18 c23">2. Gait </span></h1><h1 class="c102 c57" id="h.oj5yywtal9t4"><span class="c18">Literature </span><sup><a href="#cmnt14" id="cmnt_ref14">[n]</a></sup><span class="c18">revie</span><span class="c18">w (Gait)</span><sup><a href="#cmnt15" id="cmnt_ref15">[o]</a></sup></h1><p class="c13"><span class="c2">To understand how the gait parameters can serve as early biomarkers for Mild Cognitive Impairment (MCI), several studies were reviewed . These studies highlight several specific gait characteristics such as cadence , stride time, and double support duration. These differ significantly between individuals with normal cognition and those with MCI. </span></p><p class="c4 c11"><span class="c18 c22"></span></p><p class="c4"><span class="c18 c22">Table 1. Summary of gait -related studies on MCI detection </span></p><p class="c4 c11"><span class="c18 c22"></span></p><table class="c33"><tr class="c10"><td class="c82" colspan="1" rowspan="1"><p class="c19"><span class="c18 c23">No.</span></p></td><td class="c53 c101" colspan="1" rowspan="1"><p class="c19"><span class="c23 c44 c32">Author/Year </span></p></td><td class="c25 c101" colspan="1" rowspan="1"><p class="c19"><span class="c23 c44 c32">Context</span></p></td><td class="c80 c101" colspan="1" rowspan="1"><p class="c19"><span class="c23 c44 c32">Key Gait features Examined </span></p></td><td class="c51 c101" colspan="1" rowspan="1"><p class="c19"><span class="c23 c44 c32">Findings </span></p><p class="c19"><span class="c23 c44 c32">(MCI vs Healthy)</span></p></td><td class="c98 c101" colspan="1" rowspan="1"><p class="c19"><span class="c23 c44 c32">Relevance to our project </span></p></td></tr><tr class="c10"><td class="c82" colspan="1" rowspan="1"><p class="c19"><span class="c18 c23">1</span></p></td><td class="c53" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td><td class="c80" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td><td class="c51" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td><td class="c98" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td></tr><tr class="c10"><td class="c82" colspan="1" rowspan="1"><p class="c19"><span class="c18 c23">2</span></p></td><td class="c53" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td><td class="c80" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td><td class="c51" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td><td class="c98" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td></tr><tr class="c10"><td class="c82" colspan="1" rowspan="1"><p class="c19"><span class="c18 c23">3</span></p></td><td class="c53" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td><td class="c80" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td><td class="c51" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td><td class="c98" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td></tr><tr class="c10"><td class="c82" colspan="1" rowspan="1"><p class="c19"><span class="c18 c23">4</span></p></td><td class="c53" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td><td class="c80" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td><td class="c51" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td><td class="c98" colspan="1" rowspan="1"><p class="c1"><span class="c18 c23"></span></p></td></tr></table><p class="c13"><span class="c2">Collectively , these studies suggests that gait reflects both motor and cognitive integrity. Slower cadence ,longer stride time and greater double support duration are consistent making them suitable for non- invasive MCI screening .</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span class="c66 c32">Data Collection &amp; Prototype (Piradnya)</span><sup><a href="#cmnt16" id="cmnt_ref16">[p]</a></sup><sup><a href="#cmnt17" id="cmnt_ref17">[q]</a></sup></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c13"><span class="c2">Features of Gait that are potentially indicative of MCI such as cadence, stride length, and support time can be extracted from accelerometer signals. Metabase sensor was placed on the thigh to recreate previous gait data collection protocol. Accelerometer data was successfully collected and analysed by converting to thigh gait angles.</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 637.84px; height: 200.08px;"><img alt="" src="images/image34.png" style="width: 637.84px; height: 200.08px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c27"><span class="c24">Figure : Thigh angle gait plot (Left: Test data, Right: Established Literature (Abhayasinghe &amp; Murray, 2014))</span><sup><a href="#cmnt18" id="cmnt_ref18">[r]</a></sup></p><p class="c27 c11"><span class="c14"></span></p><p class="c13"><span class="c2">In the established thigh gait cycle, the gait phases are distinguished within a very close margin. This is because device placement is further away from main joints (knee, ankle, hip) which are commonly used for gait analysis. In the case of MCI patients, this threshold is reduced even more due to irregular gait, causing phases to be similar to each other and hence increase the chance of unclear event detection.</span></p><p class="c8"><span class="c2"></span></p><p class="c13"><span>Due to these limitations, we ideated for a different location, the ankle (lower lateral shank) to collect gait data (</span><span>Panebianco et al., 2020</span><sup><a href="#cmnt19" id="cmnt_ref19">[s]</a></sup><span>; </span><span>Vargas-Valencia et al., 2016</span><sup><a href="#cmnt20" id="cmnt_ref20">[t]</a></sup><span>; </span><span>Trojaniello et al., </span><sup><a href="#cmnt21" id="cmnt_ref21">[u]</a></sup><span class="c2">2014) .</span></p><p class="c8"><span class="c2"></span></p><p class="c13"><span class="c2">Testing encompassed securing the Metabase sensor to the ankle and performing daily activities (walking in a straight line, up/down slope and up/down stairs). From the ankle data collected, significant gait features were identifiable from raw and minimally processed data. Additionally, ankle gait was distinct, cyclic and resilient to daily activities. </span></p><p class="c8"><span class="c2"></span></p><p class="c13"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 667.82px; height: 154.20px;"><img alt="" src="images/image15.png" style="width: 667.82px; height: 154.20px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c8"><span class="c2"></span></p><p class="c27"><span class="c14">Figure: Raw accelerometer data (x,y,z,magnitude)</span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c13"><span class="c2">Furthermore, literature shows that raw accelerometer gait (1-axis) can be used to differentiate between normal and altered walk. Similarly, a conversion to frequency domain can enable the quantification of cadence (frequency of steps) associated with normal and altered walk.</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 349.33px;"><img alt="" src="images/image2.png" style="width: 601.70px; height: 349.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c27"><span class="c24">Figure: Walking characteristics from raw and FFT accelerometer data (Canonico et al., 2023b)</span><sup><a href="#cmnt22" id="cmnt_ref22">[v]</a></sup></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span class="c2">This substantiates the idea that ankle data is more significant for our purpose of MCI gait detection from daily movement.</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span class="c2">Furthermore, previous trials performed by the NUS research team showed insights into difficulties with adherence of gait sensors to the thigh. We have ideated and improved the mode of securing gait sensor using velcro based straps that house the sensor.</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 529.00px; height: 211.00px;"><img alt="" src="images/image10.png" style="width: 529.00px; height: 211.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c27"><span class="c14">Figure: Velcro Strap band housing Sensor</span></p><p class="c4 c11"><span class="c14"></span></p><p class="c4"><span class="c2">This provides a secure attachment of the sensor to the ankle and enables an easier method of device attachment for the elderly MCI participants.</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span class="c66 c32">Gait Data </span><span class="c66 c32">Analysis </span><sup><a href="#cmnt23" id="cmnt_ref23">[w]</a></sup><sup><a href="#cmnt24" id="cmnt_ref24">[x]</a></sup><span class="c18 c23">(Piradnya)</span></p><p class="c4"><span class="c2">(explain Vicon)</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span>For Gait Data and testing, we are using previously collected Vicon based and Metawear (3-axis accelerometer) based data collected on healthy test participants. Vicon is an industry standard motion capture system that uses infrared cameras to detect reflective markers strategically placed on the participants. The Vicon software is then used to process the gait movement of participants with respect to time and space, identifying and quantifying gait features </span><span>(Vicon Motion Systems, 2025)</span><sup><a href="#cmnt25" id="cmnt_ref25">[y]</a></sup><span class="c2">.</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span>During participant V</span><span>icon</span><span>&nbsp;data collection, an older version of the metabase sensor was attached to the participants&#39; left and right lower shank (ankle). The legacy code was developed to match the older sensor version with the Vicon data. The aim is to improve features and constants of the legacy code for the new Metabase sensor version (which replicates 3- axis accelerometer based research sensor), using the V</span><span>icon</span><span class="c2">&nbsp;processed data for validation. </span></p><p class="c28 c11"><span class="c29"></span></p><p class="c28"><span class="c18 c90 c76">Improve feature detection within gait data sets</span></p><p class="c28 c11"><span class="c29"></span></p><p class="c28"><span class="c76">Looking closely into the accelerometer data processing, each gait cycle will have a similar pattern and features (Figure). As mentioned previously, gait has certain distinct events. We need to ensure during analysis, our algorithm is able to distinguish these events from the processed data. </span></p><p class="c4 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c11 c16"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><p class="c16 c11"><span class="c2"></span></p><table class="c121"><tr class="c120"><td class="c87 c91" colspan="1" rowspan="1"><p class="c26"><span class="c23 c75 c32">Features</span></p></td><td class="c72" colspan="1" rowspan="1"><p class="c26"><span class="c23 c32 c75">Expected</span></p></td></tr><tr class="c84"><td class="c87" colspan="1" rowspan="1"><p class="c26"><span class="c2">TO (Toe Off)</span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c26"><span>-0.3 rad/s</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 42.86px; height: 51.99px;"><img alt="" src="images/image18.png" style="width: 42.86px; height: 51.99px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c84"><td class="c87" colspan="1" rowspan="1"><p class="c26"><span class="c2">Msw (Mid Swing)</span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c26"><span>0 rad/s</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 49.60px; height: 42.87px;"><img alt="" src="images/image12.png" style="width: 49.60px; height: 42.87px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c84"><td class="c87" colspan="1" rowspan="1"><p class="c26"><span class="c2">Tst (Terminal Stance)</span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c26"><span>0.1 rad/s</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 56.22px; height: 32.74px;"><img alt="" src="images/image24.png" style="width: 56.22px; height: 32.74px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c60"><td class="c87" colspan="1" rowspan="1"><p class="c26"><span class="c2">Psw (Pre Swing)</span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c26"><span>0.05 rad/s</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 42.86px; height: 55.46px;"><img alt="" src="images/image20.png" style="width: 42.86px; height: 55.46px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c84"><td class="c87" colspan="1" rowspan="1"><p class="c26"><span class="c2">Tsw (Terminal Swing)</span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c26"><span>0.1 rad/s</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 49.60px; height: 40.94px;"><img alt="" src="images/image31.png" style="width: 49.60px; height: 40.94px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c84"><td class="c87" colspan="1" rowspan="1"><p class="c26"><span class="c2">HS (Heel Strike)</span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c26"><span>0 rad/s</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 49.60px; height: 51.99px;"><img alt="" src="images/image6.png" style="width: 49.60px; height: 51.99px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr></table><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 343.00px; height: 387.33px;"><img alt="" src="images/image14.png" style="width: 343.00px; height: 387.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c1"><span class="c24 c31"></span></p><p class="c19"><span class="c24 c69 c83">Figure</span><span class="c31 c24">: Features in 1 gait cycle &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Table: Features in 1 gait cycle</span></p><p class="c1"><span class="c31 c24"></span></p><p class="c11 c21"><span class="c44 c24 c83 c32 c114"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c1"><span class="c29"></span></p><p class="c1"><span class="c29"></span></p><p class="c28"><span class="c29">The image below shows 1 set of gait data collected from the right ankle of a healthy participant. This data set will be used in the report for further explanation of gait data analysis.</span></p><p class="c1"><span class="c29"></span></p><p class="c19"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 200.00px;"><img alt="" src="images/image32.png" style="width: 601.70px; height: 200.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c26"><span class="c5">Figure: Gait event detection (unmodified code)</span></p><p class="c1"><span class="c29"></span></p><p class="c28"><span class="c76">The legacy code is able to determine and mark most gait features. However, there are a few missing features</span><span class="c62 c44 c67">. Specifically, Terminal swing (TSW_onset) is incorrect in the 2nd gait along with TSW_onset, Toe Off and Heel Strike identifications missing in the 4th gait cycle.</span></p><p class="c28 c11"><span class="c62 c44 c67"></span></p><p class="c28"><span class="c62 c44 c67">Looking into the code flow in further detail, a potential root cause was identifiable.</span></p><p class="c1"><span class="c29"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 302.67px;"><img alt="" src="images/image23.png" style="width: 601.70px; height: 302.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c26"><span class="c5">Figure: Legacy code flow</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c13"><span class="c2">The data processing to identify significant gait phases are dependent on the Terminal swing onset identified within each gait cycle. This identification is performed by a peak finding function. </span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c13"><span class="c2">Further analysis of the code (below figure) showed that the terminal swing and terminal stance peaks in the 2nd gait cycle are significantly close to each other. Hence, the peak finding function ignores the 2nd peaks, causing misalignment of gait features in the following gait cycles.</span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c13"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 527.50px; height: 399.84px;"><img alt="" src="images/image27.png" style="width: 533.71px; height: 399.84px; margin-left: -6.21px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c26"><span class="c5">Figure: Right Shank Angle Peaks</span></p><p class="c8"><span class="c2"></span></p><p class="c28"><span class="c29">In order to improve event detection, Min_sep_coeff was reduced from 0.75 to 0.2,resulting in the proper identification of gait features (figure below). &quot;min_sep_coeff&quot; &nbsp;is used to distinguish and decide the minimum duration between the same events over different cycles. By reducing this, the new code is able to accurately detect all missing features such as right heel strike, Toe off and Terminal Swing onset via reducing constant. </span></p><p class="c28 c11"><span class="c29"></span></p><p class="c28 c11"><span class="c29"></span></p><p class="c28"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 193.33px;"><img alt="" src="images/image8.png" style="width: 601.70px; height: 193.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c26"><span class="c5">Figure: Gait event detection (modified code)</span></p><p class="c28 c11"><span class="c29"></span></p><p class="c28 c11"><span class="c29"></span></p><p class="c28 c11"><span class="c29"></span></p><p class="c28"><span class="c18 c90 c76">Reduce discrepancy within features identified by code and Vicon</span></p><p class="c28 c11"><span class="c18 c76 c90"></span></p><p class="c28 c11"><span class="c29"></span></p><p class="c28"><span class="c29">Features such as Cadence, Step time and Stride length calculated by the legacy code closely match Vicon processed data with an average 5% error throughout all participants. However, features such as Foot off and opposite Foot off present high percentages of error (&gt;100%). Hence, the primary aim is to identify strategies to reduce this error. The future aim would be to achieve accuracy close to Vicon processed data. </span></p><p class="c28 c11"><span class="c29"></span></p><p class="c28 c11"><span class="c29"></span></p><p class="c28"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 239.54px;"><img alt="" src="images/image33.png" style="width: 601.70px; height: 239.54px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c28 c11"><span class="c29"></span></p><p class="c26"><span class="c5">Table: Percentage (%) feature error comparison</span></p><p class="c28 c11"><span class="c29"></span></p><p class="c28 c11"><span class="c29"></span></p><p class="c28"><span class="c76">Foot off is the percentage of the gait cycle the foot is off the ground. Opposite foot off is the percentage for which the opposite foot is off the ground with respect to the current leg gait cycle </span><span class="c76">(Vicon Motion Systems, 2019)</span><sup><a href="#cmnt26" id="cmnt_ref26">[z]</a></sup><span class="c29">. </span></p><p class="c28 c11"><span class="c29"></span></p><p class="c28"><span class="c29">From analysing and comparing the processed data results outputted by the old code and Vicon, &nbsp;Foot off (%) was consistently lower and Opp foot off (% ) was consistently higher.</span></p><p class="c28 c11"><span class="c29"></span></p><p class="c28"><span class="c29">This ratio was constant, enabling the identification that Foot off needs to be increased to ~280% of the value and Opp Foot off needs to be decreased to ~35% of the value. The ratio difference can be potentially attributed to changes due to different versions of the commercial metabase sensor.</span></p><p class="c11 c28"><span class="c29"></span></p><p class="c28"><span class="c29">This modification reduced errors with each feature value across data sets averaging &lt; 50% error in comparison to VICON data.</span></p><p class="c28 c11"><span class="c29"></span></p><p class="c28 c11"><span class="c29"></span></p><p class="c28 c11"><span class="c29"></span></p><p class="c13"><span>TO EXPLAIN VICON AND METABASE FOOT OFF &amp; OPP FOOT OFF RATIO CHANGE (EXCEL). </span><sup><a href="#cmnt27" id="cmnt_ref27">[aa]</a></sup><sup><a href="#cmnt28" id="cmnt_ref28">[ab]</a></sup><sup><a href="#cmnt29" id="cmnt_ref29">[ac]</a></sup></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><h1 class="c57 c109" id="h.vsuye0dy77c"><span class="c15">3. Speech </span></h1><h1 class="c102 c57" id="h.97lpo4jdwq71"><span class="c18">Literature review (</span><span class="c18">Speech</span><sup><a href="#cmnt30" id="cmnt_ref30">[ad]</a></sup><span class="c18">)</span></h1><ul class="c37 lst-kix_7c2l7ez6h3gu-0 start"><li class="c13 c17 li-bullet-0"><span class="c2">How speech relates to MCI identification (address why speech for MCI)</span></li><li class="c13 c17 li-bullet-0"><span class="c2">Existing research regarding speech and identification of MCI (canary, winterlight labs) &nbsp;</span></li></ul><ul class="c37 lst-kix_7c2l7ez6h3gu-1 start"><li class="c13 c30 li-bullet-0"><span class="c2">Explain all the tasks etc</span></li><li class="c13 c30 li-bullet-0"><span class="c2">Table (tasks and explanation)</span></li><li class="c13 c30 li-bullet-0"><span class="c2">pratt software (phonemes and intervals etc) </span></li></ul><p class="c4 c11"><span class="c18 c22"></span></p><p class="c4"><span class="c18 c22">Table 1. Summary of Speech -related studies on MCI detection </span></p><p class="c4 c11"><span class="c18 c22"></span></p><table class="c108"><tr class="c129"><td class="c81 c101" colspan="1" rowspan="1"><p class="c19"><span class="c23 c44 c32">Author/Year </span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c19"><span class="c23 c44 c32">Context</span></p></td><td class="c80 c101" colspan="1" rowspan="1"><p class="c19"><span class="c23 c44 c32">Key Speech features Examined </span></p></td><td class="c104 c101" colspan="1" rowspan="1"><p class="c19"><span class="c23 c44 c32">Findings </span></p><p class="c19"><span class="c23 c44 c32">(MCI vs Healthy), </span></p></td><td class="c89 c101" colspan="1" rowspan="1"><p class="c19"><span class="c23 c44 c32">Relevance to our project </span></p></td></tr><tr class="c10"><td class="c81" colspan="1" rowspan="1"><p class="c16"><span class="c74">(van den Berg et al. (2024)</span></p></td><td class="c92" colspan="1" rowspan="1"><p class="c49"><span class="c74 c83">Evaluated the feasibility, reliability, and amyloid-&beta; (A&beta;) associations of remote, multi-day tablet-based speech assessments in cognitively unimpaired older adults (preclinical AD stage)</span></p></td><td class="c80" colspan="1" rowspan="1"><p class="c28"><span class="c23 c47">Temporal and acoustic features such as pause-to-word ratio, pause duration, phonation rate, fundamental frequency, intensity variance, jitter, shimmer</span></p></td><td class="c104" colspan="1" rowspan="1"><p class="c28"><span class="c23 c47">A&beta;-positive (preclinical) individuals showed more pauses (higher pause-to-word ratio) and lower phonation rate compared to A&beta;-negative; trends similar to early MCI speech decline. Multi-day averaging improved test-retest reliability (ICC &ge; 0.75)</span></p></td><td class="c89" colspan="1" rowspan="1"><p class="c28"><span class="c74">Supports using pausing behavior and phonation rate as early digital biomarkers for cognitive decline, justifies our focus on speech timing metrics from throat accelerometer data, and a multi-day, at-home data collection approach for consistent screening.</span></p></td></tr><tr class="c10"><td class="c81" colspan="1" rowspan="1"><p class="c16"><span class="c74">(Federation University, 2025, May 30)</span></p></td><td class="c92" colspan="1" rowspan="1"><p class="c28"><span class="c23 c47">AI-based speech analysis tool for early Alzheimer&rsquo;s detection using multimodal input &mdash; both linguistic (text) and acoustic (sound) features. </span></p></td><td class="c80" colspan="1" rowspan="1"><p class="c28"><span class="c23 c47">Linguistic features: Vocabulary richness, sentence complexity, word choice, and semantic coherence. Acoustic features: Pitch, rhythm, pauses,a nd fluency patterns </span></p></td><td class="c104" colspan="1" rowspan="1"><p class="c28"><span class="c23 c47">People with Alzheimer s use simpler vocabulary, fewer details, and show pauses or irregular prosody compared to healthy controls. The AI model combining text+sound improves classification accuracy for early cognitive decline </span></p></td><td class="c89" colspan="1" rowspan="1"><p class="c28"><span class="c23 c47">Supports multimodal AI speech analysis as a non-invasive early screening tool.Reinforces using acoustic and linguistic metrics to detect subtle speech and fluency changes in early MCI, using picture description tasks for cognitive assessment </span></p></td></tr><tr class="c10"><td class="c81" colspan="1" rowspan="1"><p class="c19"><span class="c23 c47">(Mart&iacute;nez-Nicol&aacute;s et al., 2023)</span></p></td><td class="c92" colspan="1" rowspan="1"><p class="c28"><span class="c23 c47">Evaluate how combining reading and lexical semantic retrieval tasks improves speech-based screening for MCI and Alzheimer&rsquo;s disease (AD)</span></p></td><td class="c80" colspan="1" rowspan="1"><p class="c28"><span class="c23 c47">Extracted acoustiv and rhythmic features (speech, rate, articulation rate, pauses, formants, jitter shimmers,HNR,AVQI)</span></p></td><td class="c104" colspan="1" rowspan="1"><p class="c28"><span class="c23 c47">MCI showed a slower rate, more jitter, and rhythm changes; combining tasks improved accuracy up to 83.3%</span></p></td><td class="c89" colspan="1" rowspan="1"><p class="c28"><span class="c23 c47">Supports using multi-task speech test and acoustic-temporal metrics to improve early MCI detection </span></p></td></tr><tr class="c10"><td class="c81" colspan="1" rowspan="1"><p class="c19"><span class="c23 c47">L&oacute;pez-de-Ipi&ntilde;a et al. (2013)</span></p></td><td class="c92" colspan="1" rowspan="1"><p class="c28"><span class="c23 c47">Developed a non-invasive, low-cost method for early detection of Alzheimer&#39;s using spontaneous speech and emotional response analysis </span></p></td><td class="c80" colspan="1" rowspan="1"><p class="c28"><span class="c23 c47">Features extracted vis Praat software and MATLAB: Pitch.HNR, Pause duration, voice ratio, and emotional temperature </span></p></td><td class="c104" colspan="1" rowspan="1"><p class="c28"><span class="c23 c47">AD and MCI patients had slower, less fluent speech, fewer voiced segments, and lower emotional temperature, achieving up to 93% classification accuracy using combined features </span></p></td><td class="c89" colspan="1" rowspan="1"><p class="c28"><span class="c23 c47">Supports analyzing natural speech and emotion-related cues (pauses, pitch jitter ) as early, non-invasive markers for cognitive decline in MCI.</span></p></td></tr></table><h2 class="c54" id="h.tr6do8sncc07"><span class="c18 c23"></span></h2><h2 class="c103" id="h.umpv2roabnly"><span class="c18 c23">Conclusion from Speech Literature: How Speech relates to MCI identification </span></h2><p class="c13"><span>Speech is closely linked to cognitive processes such as memory, attention, and language, making it a sensitive indicator of early cognitive decline. In mild cognitive impairment (MCI), subtle changes can be observed, for example, people tend to speak more slowly, pause more often, and show reduced fluency. Their language also becomes simpler, with a more limited vocabulary and less coherent expression. The review it shows that acoustic features like pause duration, speech rate, jitter, and phonation stability can reliably distinguish MCI from healthy aging, reflecting the brain&rsquo;s reduced efficiency in language planning and </span><span>retrieval. As</span><span class="c2">&nbsp;a result, speech analysis has become a promising non-invasive tool for early MCI detection and continuous cognitive monitoring.</span></p><h2 class="c103" id="h.hx7yd15vq749"><span class="c18 c23">Recent studies by companies for Speech Testing for MCI </span></h2><h2 class="c127" id="h.q3sexp7pys8b"><span class="c69">Recent studie</span><sup><a href="#cmnt31" id="cmnt_ref31">[ae]</a></sup><span class="c69">s by Canary Speech and Winterlight Labs show that speech can serve as a sensitive digital biomarker for early cognitive decline. Using AI-driven analysis of both acoustic (rate, pauses, pitch) and linguistic (word choice, syntax) features, these systems detect subtle speech changes linked to mild cognitive impairment (MCI) and Alzheimer&rsquo;s disease. Winterlight Labs demonstrated that remote speech tasks such as picture description and story recall are reliable and that higher pause-to-word ratios correlate with amyloid-&beta; pathology </span><span class="c41 c69">(van den Berg et al., 2024)</span><span class="c69">. Canary Speech similarly applies multimodal AI models to analyze tone and word use, achieving accurate differentiation between MCI and healthy individuals </span><span class="c41 c69">(Federation University, 2025; Hilsabeck et al., 2025).</span><span class="c2">&nbsp;Together, these studies support speech as a non-invasive, scalable tool for early MCI screening.</span></h2><h2 class="c103" id="h.7x48u3kgfroo"><span class="c18 c23">Software used to detect Speech analysis &nbsp;(Praat Software)</span></h2><table class="c94"><tr class="c10"><td class="c0" colspan="1" rowspan="1"><p class="c19"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 189.33px;"><img alt="" src="images/image19.png" style="width: 286.00px; height: 189.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c14">Praat software for measuring speech frequency </span></p></td><td class="c65" colspan="1" rowspan="1"><p class="c28"><span class="c2">Praat is an open-source software used to analyze detailed speech characteristics such as phoneme duration, pause intervals, pitch (F0), formants, intensity, jitter, and shimmer. It segments speech into phonemes and silence intervals, allowing precise measurement of timing and prosody. These features are vital for detecting MCI-related changes, as longer pauses, slower articulation, and reduced pitch variation often reflect early cognitive decline and impaired language control.</span></p></td></tr></table><h2 class="c54" id="h.rgok6xjisobn"><span class="c23 c44 c32"></span></h2><h2 class="c103" id="h.7d0gvrxn9ghc"><span class="c23 c44 c32">[pt 12: Data collection methods]</span></h2><ul class="c37 lst-kix_7c2l7ez6h3gu-0"><li class="c13 c17 li-bullet-0"><span class="c2">Ours is different BECAUSE: tasks table &rarr; how we concluded on using constrained tasks</span></li><li class="c8 c17 li-bullet-0"><span class="c2"></span></li></ul><p class="c13 c46"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 345.33px;"><img alt="" src="images/image22.png" style="width: 601.70px; height: 345.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c8"><span class="c2"></span></p><h2 class="c103" id="h.sopk3cnsm0xz"><span class="c18">Pt 13: Speech Testing - Backwards counting (</span><span class="c18">200Hz</span><sup><a href="#cmnt32" id="cmnt_ref32">[af]</a></sup><span class="c18">)</span></h2><p class="c4 c11"><span class="c18 c23"></span></p><p class="c4"><span class="c2">To analyze speech-related vibrations for potential detection of mild cognitive impairment (MCI), a simple and repeatable task was first chosen. The task was to count backwards from 305 to 285. </span></p><p class="c4"><span class="c2">This task was an effective baseline to establish the normal speech vibration pattern as it is :</span></p><ul class="c37 lst-kix_g3v6ucj702wq-0 start"><li class="c4 c17 li-bullet-0"><span class="c2">Structured and easy to reproduce in a clinical setting</span></li><li class="c4 c17 li-bullet-0"><span class="c2">Short, reducing fatigue in performance </span></li><li class="c4 c17 li-bullet-0"><span class="c2">Consistent, allowing comparison between normal and impaired speech behaviours </span></li></ul><p class="c4 c11"><span class="c23 c75 c106"></span></p><h4 class="c48" id="h.6df5omwya3cl"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 534.50px; height: 357.22px;"><img alt="" src="images/image11.png" style="width: 534.50px; height: 357.22px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><sup><a href="#cmnt33" id="cmnt_ref33">[ag]</a></sup><sup><a href="#cmnt34" id="cmnt_ref34">[ah]</a></sup></h4><p class="c48 c11"><span class="c18 c23"></span></p><p class="c48 c11"><span class="c18 c23"></span></p><table class="c70"><tr class="c112"><td class="c39" colspan="2" rowspan="1"><p class="c57 c59"><span class="c23 c44 c32">Backwards counting Review</span></p></td></tr><tr class="c112"><td class="c20" colspan="1" rowspan="1"><p class="c48"><span class="c23 c44 c32">Why 200 Hz Change to 400 Hz</span></p></td><td class="c58" colspan="1" rowspan="1"><p class="c48"><span class="c23 c32 c44">Why backward counting is rejected </span></p></td></tr><tr class="c124"><td class="c20" colspan="1" rowspan="1"><p class="c3 c57"><span>Prior work shows that vibrations at the skin surface of the neck (induced by phonation and vocal tract activity) include significant spectral content </span><span class="c24">up to at least ~300 Hz</span><span>&nbsp;</span><span class="c41">(Yang et al., 2018; Munger et al., 2008)</span><span>. Because the neck-skin system and the coupling from vocal fold/airflow to skin vibration can transmit high-frequency components </span><span class="c41">(Lee et al., 2019)</span><span class="c2">, capturing these requires a sampling frequency sufficient to avoid aliasing. A 200 Hz sampling rate would only support accurate representation of signal components up to ~100 Hz (Nyquist limit). To provide margin for higher-frequency vibration components, potential harmonics, and transient events, a 400 Hz sampling rate was selected.</span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c23 c106 c69 c111"></span></p><p class="c13"><span class="c111">Initially, the data was recorded at 200Hz, which was sufficient to capture gross throat movements. However, during early testing, the vibration waveforms appeared less detailed, and some subtle variations between syllables were not clearly visible. To improve the signal fidelity, the accelerometer&rsquo;s sampling frequency was increased to 400 Hz. By changing this adjustment, this allows higher temporal resolution for detecting finer vibration features linked to articulation and pause transitions. It only has a higher sampling rate that sup</span><span>ports a wider frequency range and more accurate comparison between speech subtasks and future datasets.</span><sup><a href="#cmnt35" id="cmnt_ref35">[ai]</a></sup></p></td><td class="c58" colspan="1" rowspan="1"><p class="c48"><span>Backward counting imposes a higher cognitive demand because it engages several executive functions simultaneously. It requires individuals to hold numbers in working memory and update them continuously. This introduces unrelated vocal mechanics. When participants concentrate intensely, they might change their speaking rhythm, loudness, or pacing, which can distort the accelerometer reading and make it harder to isolate pure vocal vibration patterns. To ensure the signals reflect speech characteristics rather than cognitive effort, we prioritized low-load, structured tasks that are easier to standardize and repeat. </span><span class="c41">(Boag et al., 2021)</span></p><p class="c48 c11"><span class="c18 c23"></span></p></td></tr></table><p class="c48 c11"><span class="c18 c23"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span class="c66 c32">Piradnya part </span><sup><a href="#cmnt36" id="cmnt_ref36">[aj]</a></sup><span class="c18 c23">-</span></p><p class="c4 c11"><span class="c18 c23"></span></p><p class="c4"><span class="c18 c23">Speech Testing - Caterpillar (Piradnya)</span></p><p class="c4 c11"><span class="c18 c23"></span></p><p class="c13"><span class="c2">Since the focus is to determine MCI individuals based on vocal characteristics of speech rather than memory and comprehension demands, a constrained fixed passage task was designated to be used as a testing protocol.</span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 485.50px; height: 266.60px;"><img alt="" src="images/image4.png" style="width: 485.50px; height: 266.60px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c27"><span class="c14">Figure: The Caterpillar Passage (Annotated)</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c48"><span class="c66 c32">Caterpillar Testing Review</span></p><p class="c13"><span>The caterpillar passage was specifically developed for a comprehensive assessment of motor-speech disorders. A relatively low verbal complexity and reading level (Flesh-Kincad Reading level of 5.0) ensures the passage can be read by most individuals. Other passage attributes encompass word repetition (enabling analysis of inconsistencies within repeated words), &nbsp;multiple intonations (enabling analysis of prosodic features such as fundamental frequency) along with a comprehensive inclusion of all English phonemes. Additionally, through vocal data collected from this moderate length passage, further features such as speech rate and number of pause can be measured </span><span>(Patel et al., 2013</span><sup><a href="#cmnt37" id="cmnt_ref37">[ak]</a></sup><span class="c2">). </span></p><p class="c8"><span class="c2"></span></p><p class="c13"><span class="c2">These extractable vibrational vocal speech features makes the Caterpillar passage ideal for accelerometer based mechanoacoustic data collection and analysis for individuals presenting with MCI. &nbsp;</span></p><p class="c8"><span class="c23 c106 c107"></span></p><p class="c13"><span class="c2">Vocal speech data via reading the caterpillar passage was collected on healthy individuals for further analysis by placing the metabase sensor (400Hz sampling rate) at the suprasternal notch.</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 49.33px;"><img alt="" src="images/image21.png" style="width: 601.70px; height: 49.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c27"><span class="c14">Figure: Sensor Placement (vocal data collection)</span></p><p class="c73"><span class="c32 c66">Conclusion for speech testing + Data collection</span><sup><a href="#cmnt38" id="cmnt_ref38">[al]</a></sup></p><p class="c68"><span>In our project, the main challenge is capturing vocal vibrations directly while keeping the signal </span><span class="c128">clear, consistent, and private </span><span class="c2">across subjects. </span></p><p class="c68"><span class="c2">Tasks such as picture descriptions, open-ended questions, and everyday speech depend heavily on context, making the data less consistent and harder to analyze. Because people talk about different topics, open-ended speech is difficult to standardize, which complicates comparisons of pauses or word patterns. It also poses challenges for sensor-based analysis, as accelerometer signals require consistent timing while spontaneous speech varies in pitch and pacing. Furthermore, open tasks lack repeatability, unlike structured ones such as the constrained task, which offer consistent and comparable data across participants.</span></p><p class="c68"><span>Since accelerometer data mainly captures physical vibrations such as pauses and fillers, standardization is important. From our review, we found that the </span><span class="c32">caterpillar task </span><span class="c2">give the most consistent and reliable signals for analysis.</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c18 c23"></span></p><p class="c4"><span class="c18 c23">Speech Data Analysis (Piradnya)</span></p><p class="c4 c11"><span class="c18 c23"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 457.50px; height: 252.80px;"><img alt="" src="images/image9.png" style="width: 457.50px; height: 252.80px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c27"><span class="c14">Figure: Vocal Data Processing Flow</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c13"><span>Using the research sensor, we collect 3 axis accelerometer data. This captures raw vocal vibrational data in the x, y and z axis at the suprasternal notch. &nbsp;In order to analyse the various features, it is important to first convert the 3 axis vector to 1 axis by performing Euclidean normalisation (</span><span>Matic et al., 2012</span><sup><a href="#cmnt39" id="cmnt_ref39">[am]</a></sup><span class="c2">). This provides an orientation independent representation of the captured vocal vibrational magnitude.</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c27"><span>Accelerometer Vector Magnitude = &radic;X</span><span class="c93">acc</span><span class="c56">2</span><span>&nbsp;+ Y</span><span class="c93">acc</span><span class="c56">2</span><span>&nbsp;+ Z</span><span class="c93">acc</span><span class="c56">2</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c13"><span>A bandpass filter is proposed to filter noise from the raw signal with cutoff frequencies that encompass 100Hz-200Hz which are the vocal vibrational frequencies of both male and female respectively. The in-built python butterworth filter function was used to perform the filtering of noise. Using the filtered signal, features such as pauses and speech rate are extractable (</span><span class="c41">Subramanian et al., 2024</span><sup><a href="#cmnt40" id="cmnt_ref40">[an]</a></sup><span class="c41">; </span><span class="c41">Huang et al., 2024b</span><sup><a href="#cmnt41" id="cmnt_ref41">[ao]</a></sup><span class="c2">).</span></p><p class="c8"><span class="c2"></span></p><p class="c13"><span>Due to the Nyquist-Shannon frequency sampling theorem, which suggests that in order to accurately reconstruct analog signals (vocal vibration accelerometer data) as a digital signal, the sampling frequency must be double the analog signal frequency being analysed (</span><span>Lai, 2003</span><sup><a href="#cmnt42" id="cmnt_ref42">[ap]</a></sup><span class="c2">). Hence, a 400 Hz sampling frequency rate (fs) is also proposed.</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 333.33px;"><img alt="" src="images/image25.png" style="width: 601.70px; height: 333.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c27"><span class="c14">Figure: Vocal data (caterpillar passage, healthy individual), accelerometer magnitude</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c13"><span class="c2">This raw signal then undergoes Fast Fourier Transformation (FFT). Conversion of the vocal signal to a frequency time domain, enables quantitative analysis of significant vocal vibrational features such as Fundamental frequency, Jitter and shimmer in speech (Huang et al., 2024b). </span></p><p class="c8"><span class="c2"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 320.00px;"><img alt="" src="images/image30.png" style="width: 601.70px; height: 320.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c27"><span class="c14">Figure: Vocal data (caterpillar passage, healthy individual), FFT</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c13"><span class="c2">Hence, by processing the vocal accelerometer signal in the time domain &nbsp;and frequency domain, the following significant parameters are extractable and potentially reflective of MCI (as mentioned in literature review segment).</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 206.67px;"><img alt="" src="images/image1.png" style="width: 601.70px; height: 206.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c27"><span class="c14">Table: Quantitative parameters (Huang et al., 2024b)</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c13"><span>Furthermore, additional processing is commonly performed to convert the vocal data to a Mel Frequency Plot, a visual representation of vocal data, and can enable further differentiation between Healthy and MCI individuals via identification of features such as Mel frequency coefficients (Huang et al., 2024b; </span><span>Dubey et al., 2020</span><sup><a href="#cmnt43" id="cmnt_ref43">[aq]</a></sup><span>;</span><span>&nbsp;Kwon et al., 2024</span><sup><a href="#cmnt44" id="cmnt_ref44">[ar]</a></sup><span class="c2">) However, these plots are often used as inputs for deep learning models and hence is a future scope.</span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 343.50px; height: 228.58px;"><img alt="" src="images/image13.png" style="width: 343.50px; height: 228.58px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c8"><span class="c2"></span></p><p class="c27"><span class="c24">&nbsp;Figure: Mel spectrogram (Roberts, 2024)</span><sup><a href="#cmnt45" id="cmnt_ref45">[as]</a></sup></p><p class="c8"><span class="c2"></span></p><p class="c13"><span class="c2">In order to narrow down suitable and informative features that are potentially indicative of MCI, the proposed idea is as follows. Collect vocal recordings of MCI patients performing constrained reading tasks from established sources and recreate/emulate the vocal recordings to collect the accelerometer data. Perform the same constrained reading task on healthy individuals and collect vocal accelerometer data for comparison. Once we have both datasets, we will compare to identify measurable acoustic differences to narrow down the parameters along with the thresholds.</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 109.33px;"><img alt="" src="images/image29.png" style="width: 601.70px; height: 109.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c27"><span class="c14">Figure : Vocal data collection &amp; analysis</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span class="c66 c32">Evaluation for </span><span class="c66 c32">speech</span><sup><a href="#cmnt46" id="cmnt_ref46">[at]</a></sup></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span>Praat is a speech analysis software, widely used in the speech research space as it offers various methods for &ldquo;analysis, synthesis, and manipulation of speeches&rdquo; </span><span>(Raju et al., 2022)</span><sup><a href="#cmnt47" id="cmnt_ref47">[au]</a></sup><span class="c2">. </span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 367.19px;"><img alt="" src="images/image28.png" style="width: 602.00px; height: 476.00px; margin-left: 0.00px; margin-top: -108.81px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c27"><span class="c24">Figure: Features of Praat software (</span><span class="c24">Praat: Doing Phonetics by Computer, n.d.</span><sup><a href="#cmnt48" id="cmnt_ref48">[av]</a></sup><span class="c14">)</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span>Using this established software, we can potentially identify quantifiable vocal features. Due to the availability of a multitude of speech analysis and synthesis options, we will look into using Praat to evaluate the vocal speech data. </span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span class="c18 c23">Overview of Speech and Gait Testing &nbsp;</span></p><p class="c4 c11"><span class="c18 c23"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 611.50px; height: 399.20px;"><img alt="" src="images/image16.png" style="width: 611.50px; height: 399.20px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c3"><span>On the left, the </span><span class="c32">gait module</span><span class="c2">&nbsp;uses a Metabase sensor to record motion data, detect heel-strike and toe-off, and extract features like stride time, cadence, and step variability, validated with VICON.</span></p><p class="c3"><span>On the right, the </span><span class="c32">speech module</span><span class="c2">&nbsp;uses the same sensor to capture vibration data, process it through filtering and spectrograms, and extract features such as pause duration, speech rate, and fundamental frequency.</span></p><p class="c3"><span class="c2">Both modules feed into a shared database, a research prototype to study how gait and speech changes can indicate early cognitive decline.</span></p><p class="c4"><span class="c66 c32">Future direction of the project</span></p><p class="c4 c46"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 622.50px; height: 301.94px;"><img alt="" src="images/image5.png" style="width: 622.50px; height: 301.94px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c3"><span class="c2">For semester 2 , We&rsquo;ll start by cleaning and optimizing our existing Python scripts to standardize the data analysis process for both gait and speech. Patient data collection will also begin in this phase.</span></p><p class="c3"><span class="c32">Weeks 4 to 6 &ndash; Testing Sensors<br></span><span class="c2">&nbsp;Next, we&rsquo;ll conduct controlled trials using Prof Wu&rsquo;s device to compare signal quality and event detection accuracy between systems.</span></p><p class="c3"><span class="c32">Weeks 7 to 9 &ndash; Patient Testing and Data Collection<br></span><span class="c2">&nbsp;We&rsquo;ll collaborate with clinicians for pilot testing, recording gait and speech data, and refining our algorithms based on feedback.</span></p><p class="c3"><span class="c32">Weeks 10 to 12 &ndash; Validation and System Evaluation<br></span><span class="c2">&nbsp;This phase focuses on validating our IMU results against neuropsychological data to assess the accuracy and reliability of our analysis.</span></p><p class="c3"><span class="c32">Week 13 &ndash; Final presentation<br></span><span>&nbsp;Finally, present our report based on out findings.</span></p><p class="c4 c11"><span class="c18 c23"></span></p><p class="c4"><span class="c66 c32">References (APA 7)</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span class="c45">Abhayasinghe, N., &amp; Murray, I. (2014). Human GaIT phase recognition based on thigh movement computed using IMUs. 2014 IEEE Ninth International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP), 1, 1&ndash;4. </span><span class="c66 c122"><a class="c6" href="https://www.google.com/url?q=https://doi.org/10.1109/issnip.2014.6827604&amp;sa=D&amp;source=editors&amp;ust=1762857594236712&amp;usg=AOvVaw2SoCI5skCoREFHCq__PvGV">https://doi.org/10.1109/issnip.2014.6827604</a></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span class="c45">Panebianco, G. P., Bisi, M. C., Stagni, R., &amp; Fantozzi, S. (2020). Timing estimation for gait in water from inertial sensor measurements: Analysis of the performance of 17 algorithms. Computer Methods and Programs in Biomedicine, 197, 105703. </span><span class="c35"><a class="c6" href="https://www.google.com/url?q=https://doi.org/10.1016/j.cmpb.2020.105703&amp;sa=D&amp;source=editors&amp;ust=1762857594237131&amp;usg=AOvVaw3BWq8OHu_HlAoOyIlU-3Rm">https://doi.org/10.1016/j.cmpb.2020.105703</a></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span class="c45 c110">Vargas-Valencia, L., Elias, A., Rocon, E., Bastos-Filho, T., &amp; Frizera, A. (2016). An IMU-to-Body alignment method applied to human GAIT analysis. Sensors, 16(12), 2090. </span><span class="c35 c110"><a class="c6" href="https://www.google.com/url?q=https://doi.org/10.3390/s16122090&amp;sa=D&amp;source=editors&amp;ust=1762857594237434&amp;usg=AOvVaw1Nuh-LXYPTzcREaM7ko4Qm">https://doi.org/10.3390/s16122090</a></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span class="c45">Trojaniello, D., Cereatti, A., Pelosin, E., Avanzino, L., Mirelman, A., Hausdorff, J. M., &amp; Della Croce, U. (2014). Estimation of step-by-step spatio-temporal parameters of normal and impaired gait using shank-mounted magneto-inertial sensors: application to elderly, hemiparetic, parkinsonian and choreic gait. Journal of NeuroEngineering and Rehabilitation, 11(1), 152. </span><span class="c35"><a class="c6" href="https://www.google.com/url?q=https://doi.org/10.1186/1743-0003-11-152&amp;sa=D&amp;source=editors&amp;ust=1762857594237914&amp;usg=AOvVaw3pGNbVeiDNLxfPDazFrSmB">https://doi.org/10.1186/1743-0003-11-152</a></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c36"><span class="c45">Canonico, M., Desimoni, F., Ferrero, A., Grassi, P. A., Irwin, C., Campani, D., Molin, A. D., Panella, M., &amp; Magistrelli, L. (2023b). GAIT Monitoring and Analysis: A Mathematical approach. Sensors, 23(18), 7743. </span><span class="c35"><a class="c6" href="https://www.google.com/url?q=https://doi.org/10.3390/s23187743&amp;sa=D&amp;source=editors&amp;ust=1762857594238226&amp;usg=AOvVaw12u5yENyOUWf1t7qwNXUVS">https://doi.org/10.3390/s23187743</a></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c36"><span class="c45">Vicon Motion Systems. (2025, October 23). Award winning motion capture Systems | VICON. Vicon. </span><span class="c35"><a class="c6" href="https://www.google.com/url?q=https://www.vicon.com/&amp;sa=D&amp;source=editors&amp;ust=1762857594238438&amp;usg=AOvVaw35pGTrFpp5yKBtakBZCoGR">https://www.vicon.com/</a></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c36"><span class="c45">Vicon Motion Systems. (2019, November 20). What is the Plug-in Gait &ldquo;Progression Frame&rdquo; and how is it used? | Vicon. Vicon. </span><span class="c35"><a class="c6" href="https://www.google.com/url?q=https://www.vicon.com/support/faqs/what-is-the-plug-in-gait-progression-frame-and-how-is-it-used/&amp;sa=D&amp;source=editors&amp;ust=1762857594238767&amp;usg=AOvVaw23PktWd9Jz0LmS1Nstr_Ot">https://www.vicon.com/support/faqs/what-is-the-plug-in-gait-progression-frame-and-how-is-it-used/</a></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c36"><span class="c45">Patel, R., Connaghan, K., Franco, D., Edsall, E., Forgit, D., Olsen, L., Ramage, L., Tyler, E., &amp; Russell, S. (2013). &ldquo;The Caterpillar&rdquo;: A novel reading passage for assessment of Motor Speech Disorders. American Journal of Speech-Language Pathology, 22(1), 1&ndash;9. </span><span class="c35"><a class="c6" href="https://www.google.com/url?q=https://doi.org/10.1044/1058-0360(2012/11-0134&amp;sa=D&amp;source=editors&amp;ust=1762857594239148&amp;usg=AOvVaw1dBlqKsYxI9AHWRxAp-SvF">https://doi.org/10.1044/1058-0360(2012/11-0134</a></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c36"><span class="c45">Matic, A., Osmani, V., &amp; Mayora, O. (2012). Speech activity detection using accelerometer. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference, 2012, 2112&ndash;2115. </span><span class="c35"><a class="c6" href="https://www.google.com/url?q=https://doi.org/10.1109/embc.2012.6346377&amp;sa=D&amp;source=editors&amp;ust=1762857594239561&amp;usg=AOvVaw18YiD5Vf1Mo34njSwWLVMJ">https://doi.org/10.1109/embc.2012.6346377</a></span></p><p class="c36"><span class="c45">Lai, E. (2003). Converting analog to digital signals and vice versa. In Elsevier eBooks (pp. 14&ndash;49). </span><span class="c35"><a class="c6" href="https://www.google.com/url?q=https://doi.org/10.1016/b978-075065798-3/50002-3&amp;sa=D&amp;source=editors&amp;ust=1762857594239779&amp;usg=AOvVaw0qk5wYDoLZg37d5wL0tDik">https://doi.org/10.1016/b978-075065798-3/50002-3</a></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c36"><span class="c45">Roberts, L. (2024, January 17). Understanding the Mel Spectrogram. Medium. </span><span class="c35"><a class="c6" href="https://www.google.com/url?q=https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53&amp;sa=D&amp;source=editors&amp;ust=1762857594240066&amp;usg=AOvVaw3M4OwpU234sqEY7SPCzCNs">https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53</a></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c36"><span class="c45">Dubey, S., Mahnan, A., &amp; Konczak, J. (2020). Real-Time Voice Activity Detection Using Neck-Mounted Accelerometers for Controlling a Wearable Vibration Device to Treat Speech Impairment. Proceedings of the 2020 Design of Medical Devices Conference. </span><span class="c35"><a class="c6" href="https://www.google.com/url?q=https://doi.org/10.1115/dmd2020-9081&amp;sa=D&amp;source=editors&amp;ust=1762857594240438&amp;usg=AOvVaw2Pu562veuWix3REvnbJl8A">https://doi.org/10.1115/dmd2020-9081</a></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c36"><span class="c45">Kwon, J., Hwang, J., Sung, J. E., &amp; Im, C. (2024). Speech synthesis from three-axis accelerometer signals using conformer-based deep neural network. Computers in Biology and Medicine, 182, 109090. </span><span class="c35"><a class="c6" href="https://www.google.com/url?q=https://doi.org/10.1016/j.compbiomed.2024.109090&amp;sa=D&amp;source=editors&amp;ust=1762857594240763&amp;usg=AOvVaw2rK1eX48hZdCkkvGmjJ4iK">https://doi.org/10.1016/j.compbiomed.2024.109090</a></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c36"><span class="c45">Raju, A. R., Kalathinathan, A., &amp; Vally, M. (2022). SIGNIFICANCE OF PRATT SOFTWARE: UNDERSTANDING ITS PHONOLOGICAL CHARACTERISTICS AND PROSODIC FEATURES. Zenodo (CERN European Organization for Nuclear Research). </span><span class="c35"><a class="c6" href="https://www.google.com/url?q=https://doi.org/10.5281/zenodo.7327004&amp;sa=D&amp;source=editors&amp;ust=1762857594241086&amp;usg=AOvVaw0U2rjFNFVqnQ_xkg6mwX9f">https://doi.org/10.5281/zenodo.7327004</a></span></p><p class="c4 c11"><span class="c2"></span></p><p class="c36"><span class="c45">Praat: doing Phonetics by Computer. (n.d.). </span><span class="c35"><a class="c6" href="https://www.google.com/url?q=https://www.fon.hum.uva.nl/praat/&amp;sa=D&amp;source=editors&amp;ust=1762857594241262&amp;usg=AOvVaw3DiRM59NJTWIouc57BkWGw">https://www.fon.hum.uva.nl/praat/</a></span></p><p class="c36 c11"><span class="c12"></span></p><p class="c36"><span class="c42">Boag, R. J., Stevenson, N., van Dooren, R., Trutti, A. C., Sjoerds, Z., &amp; Forstmann, B. U. (2021). Cognitive Control of Working Memory: A Model-Based Approach. </span><span class="c42 c24">Brain sciences</span><span class="c42">, </span><span class="c42 c24">11</span><span class="c42">(6), 721. https://doi.org/10.3390/brainsci11060721</span></p><p class="c4 c11"><span class="c9"></span></p><p class="c4 c11"><span class="c9"></span></p><p class="c4"><span class="c42">Munger, J. B., &amp; Thomson, S. L. (2008). Frequency response of the skin on the head and neck during production of selected speech sounds. </span><span class="c42 c24">The Journal of the Acoustical Society of America</span><span class="c42">, </span><span class="c24 c42">124</span><span class="c42">(6), 4001&ndash;4012. https://doi.org/10.1121/1.3001703</span></p><p class="c4 c11"><span class="c9"></span></p><p class="c4 c11"><span class="c9"></span></p><p class="c4"><span class="c42">Lee, S., Kim, J., Yun, I., Bae, G. Y., Kim, D., Park, S., Yi, I. M., Moon, W., Chung, Y., &amp; Cho, K. (2019). An ultrathin conformable vibration-responsive electronic skin for quantitative vocal recognition. </span><span class="c42 c24">Nature communications</span><span class="c42">, </span><span class="c42 c24">10</span><span class="c42">(1), 2468. https://doi.org/10.1038/s41467-019-10465-w</span></p><p class="c4 c11"><span class="c2"></span></p><p class="c4"><span class="c105 c42">Mart&iacute;nez-Nicol&aacute;s, I., Mart&iacute;nez-S&aacute;nchez, F., Ivanova, O. </span><span class="c105 c42 c24">et al.</span><span class="c105 c42">&nbsp;Reading and lexical&ndash;semantic retrieval tasks outperforms single task speech analysis in the screening of mild cognitive impairment and Alzheimer&#39;s disease. </span><span class="c42 c24 c105">Sci Rep</span><span class="c105 c42">&nbsp;13, 9728 (2023). </span><span class="c66 c105 c42"><a class="c6" href="https://www.google.com/url?q=https://doi.org/10.1038/s41598-023-36804-y&amp;sa=D&amp;source=editors&amp;ust=1762857594242687&amp;usg=AOvVaw0AUzAwBCGvEfuxOamEY-i2">https://doi.org/10.1038/s41598-023-36804-y</a></span></p><p class="c4 c11"><span class="c55 c42"></span></p><p class="c4"><span class="c55 c42">https://www.researchgate.net/publication/255821629_On_Automatic_Diagnosis_of_Alzheimer&#39;s_Disease_Based_on_Spontaneous_Speech_Analysis_and_Emotional_Temperature/link/00463528dbe05d111f000000/download?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6InB1YmxpY2F0aW9uIiwicGFnZSI6InB1YmxpY2F0aW9uIn19</span></p><div class="c7"><p class="c19"><a href="#cmnt_ref1" id="cmnt1">[a]</a><span class="c2">specifications&nbsp;for device (research&nbsp;program)</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref2" id="cmnt2">[b]</a><span class="c2">amanda to add block diagram</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref3" id="cmnt3">[c]</a><span class="c2">find the comment i resolved oop</span></p><p class="c19"><span class="c2">overarching goal of research program: screening, clinicians</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref4" id="cmnt4">[d]</a><span class="c2">More specific project problem statement (not necessarily HMW): use signals collected&nbsp;from IMU accelerometer to identity&nbsp;gait parameters to detect MCI/ recorded signals when one is speaking to identify features for people with MCI</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref5" id="cmnt5">[e]</a><span class="c2">more elab on devices etc</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref6" id="cmnt6">[f]</a><span class="c2">@kelschoolwork10@gmail.com</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref7" id="cmnt7">[g]</a><span class="c2">research program objective</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref8" id="cmnt8">[h]</a><span class="c2">goal is to develop the wearable.</span></p><p class="c1"><span class="c2"></span></p><p class="c19"><span class="c2">these were the goals used to design the device; and our goal is to work with the signals generated from device</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref9" id="cmnt9">[i]</a><span class="c2">Explain Prof Wu&rsquo;s sensor, what the lab has done. Mention that sensors is low so we are using metabase sensor now to collect and stream</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref10" id="cmnt10">[j]</a><span class="c2">@kelschoolwork10@gmail.com @piradnya.yeshawini@gmail.com can check if this is correct</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref11" id="cmnt11">[k]</a><span class="c2">kel</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref12" id="cmnt12">[l]</a><span class="c2">project scope vs prof wu project scipe</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref13" id="cmnt13">[m]</a><span class="c2">Prof Mark mention about this if I am not wrong</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref14" id="cmnt14">[n]</a><span class="c2">paragraph talking about parameters; summarize w table</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref15" id="cmnt15">[o]</a><span class="c2">amanda in charge of gait lit review</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref16" id="cmnt16">[p]</a><span class="c2">background regarding data collected from Metabase (9 axis vs 3 axis, accelerometer)</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref17" id="cmnt17">[q]</a><span class="c2">sampling rate, dynamic range etc.</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref18" id="cmnt18">[r]</a><span class="c2">Abhayasinghe, N., &amp; Murray, I. (2014). Human GaIT phase recognition based on thigh movement computed using IMUs. 2014 IEEE Ninth International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP), 1, 1&ndash;4. https://doi.org/10.1109/issnip.2014.6827604</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref19" id="cmnt19">[s]</a><span class="c2">Panebianco, G. P., Bisi, M. C., Stagni, R., &amp; Fantozzi, S. (2020). Timing estimation for gait in water from inertial sensor measurements: Analysis of the performance of 17 algorithms. Computer Methods and Programs in Biomedicine, 197, 105703. https://doi.org/10.1016/j.cmpb.2020.105703</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref20" id="cmnt20">[t]</a><span class="c2">Vargas-Valencia, L., Elias, A., Rocon, E., Bastos-Filho, T., &amp; Frizera, A. (2016). An IMU-to-Body alignment method applied to human GAIT analysis. Sensors, 16(12), 2090. https://doi.org/10.3390/s16122090</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref21" id="cmnt21">[u]</a><span class="c2">Trojaniello, D., Cereatti, A., Pelosin, E., Avanzino, L., Mirelman, A., Hausdorff, J. M., &amp; Della Croce, U. (2014). Estimation of step-by-step spatio-temporal parameters of normal and impaired gait using shank-mounted magneto-inertial sensors: application to elderly, hemiparetic, parkinsonian and choreic gait. Journal of NeuroEngineering and Rehabilitation, 11(1), 152. https://doi.org/10.1186/1743-0003-11-152</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref22" id="cmnt22">[v]</a><span class="c2">Canonico, M., Desimoni, F., Ferrero, A., Grassi, P. A., Irwin, C., Campani, D., Molin, A. D., Panella, M., &amp; Magistrelli, L. (2023b). GAIT Monitoring and Analysis: A Mathematical approach. Sensors, 23(18), 7743. https://doi.org/10.3390/s23187743</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref23" id="cmnt23">[w]</a><span class="c2">gait image</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref24" id="cmnt24">[x]</a><span class="c2">(to be in lit review section)</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref25" id="cmnt25">[y]</a><span class="c2">Vicon Motion Systems. (2025, October 23). Award winning motion capture Systems | VICON. Vicon. https://www.vicon.com/</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref26" id="cmnt26">[z]</a><span class="c2">Vicon Motion Systems. (2019, November 20). What is the Plug-in Gait &ldquo;Progression Frame&rdquo; and how is it used? | Vicon. Vicon. https://www.vicon.com/support/faqs/what-is-the-plug-in-gait-progression-frame-and-how-is-it-used/</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref27" id="cmnt27">[aa]</a><span class="c2">Collected data with Metabase, need some way to validate Metabase with Vicon to ensure that code/ algorithm is accurate/ validated</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref28" id="cmnt28">[ab]</a><span class="c2">Reason: eventually want to work with sensors (Prof Wu&#39;s research sensor)</span></p><p class="c1"><span class="c2"></span></p><p class="c19"><span class="c2">[explain sensor/ how this is used in the context of the project/ research]</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref29" id="cmnt29">[ac]</a><span class="c2">done both</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref30" id="cmnt30">[ad]</a><span class="c2">amanda</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref31" id="cmnt31">[ae]</a><span class="c2">https://cambridgecognition.com/speech-based-biomarkers-for-monitoring-progressive-changes-in-alzheimers-disease/&nbsp; &nbsp;&nbsp;</span></p><p class="c1"><span class="c2"></span></p><p class="c19"><span class="c2">chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://canaryspeech.com/wp-content/uploads/2023/05/MCI_Japanese_Research_Report_Jan_2023.pdf&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span></p><p class="c1"><span class="c2"></span></p><p class="c19"><span class="c2">https://canaryspeech.com/blog/voice-biomarkers-accurately-detect-mci/</span></p><p class="c1"><span class="c2"></span></p><p class="c19"><span class="c2">https://pubmed.ncbi.nlm.nih.gov/36777093/</span></p><p class="c1"><span class="c2"></span></p><p class="c19"><span class="c2">https://pubmed.ncbi.nlm.nih.gov/33251474/</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref32" id="cmnt32">[af]</a><span class="c2">amanda</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref33" id="cmnt33">[ag]</a><span class="c2">can remove code</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref34" id="cmnt34">[ah]</a><span class="c2">block diagrams/ flow charts are good</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref35" id="cmnt35">[ai]</a><span class="c2">explain why backward counting may not be the most useful (because it requires high cognitive load)</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref36" id="cmnt36">[aj]</a><span class="c2">@piradnya.yeshawini@gmail.com</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref37" id="cmnt37">[ak]</a><span class="c2">Patel, R., Connaghan, K., Franco, D., Edsall, E., Forgit, D., Olsen, L., Ramage, L., Tyler, E., &amp; Russell, S. (2013). &ldquo;The Caterpillar&rdquo;: A novel reading passage for assessment of Motor Speech Disorders. American Journal of Speech-Language Pathology, 22(1), 1&ndash;9. https://doi.org/10.1044/1058-0360(2012/11-0134</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref38" id="cmnt38">[al]</a><span class="c2">Conclusion for speech&nbsp;testing +data collection</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref39" id="cmnt39">[am]</a><span class="c2">Matic, A., Osmani, V., &amp; Mayora, O. (2012). Speech activity detection using accelerometer. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference, 2012, 2112&ndash;2115. https://doi.org/10.1109/embc.2012.6346377</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref40" id="cmnt40">[an]</a><span class="c2">Subramanian, V., Kwon, N., Brueckner, R., Blaylock, N., &amp; O&rsquo;Connell, H. (2024). Detecting mild cognitive impairment using vocal biomarkers from spontaneous speech. ISCA Archive, 1&ndash;5. https://doi.org/10.21437/smm.2024-1</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref41" id="cmnt41">[ao]</a><span class="c2">Huang, L., Yang, H., Che, Y., &amp; Yang, J. (2024b). Automatic speech analysis for detecting cognitive decline of older adults. Frontiers in Public Health, 12, 1417966. https://doi.org/10.3389/fpubh.2024.1417966</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref42" id="cmnt42">[ap]</a><span class="c2">Lai, E. (2003). Converting analog to digital signals and vice versa. In Elsevier eBooks (pp. 14&ndash;49). https://doi.org/10.1016/b978-075065798-3/50002-3</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref43" id="cmnt43">[aq]</a><span class="c2">Dubey, S., Mahnan, A., &amp; Konczak, J. (2020). Real-Time Voice Activity Detection Using Neck-Mounted Accelerometers for Controlling a Wearable Vibration Device to Treat Speech Impairment. Proceedings of the 2020 Design of Medical Devices Conference. https://doi.org/10.1115/dmd2020-9081</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref44" id="cmnt44">[ar]</a><span class="c2">Kwon, J., Hwang, J., Sung, J. E., &amp; Im, C. (2024). Speech synthesis from three-axis accelerometer signals using conformer-based deep neural network. Computers in Biology and Medicine, 182, 109090. https://doi.org/10.1016/j.compbiomed.2024.109090</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref45" id="cmnt45">[as]</a><span class="c2">Roberts, L. (2024, January 17). Understanding the Mel Spectrogram. Medium. https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref46" id="cmnt46">[at]</a><span class="c2">piradnya</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref47" id="cmnt47">[au]</a><span class="c2">Raju, A. R., Kalathinathan, A., &amp; Vally, M. (2022). SIGNIFICANCE OF PRATT SOFTWARE: UNDERSTANDING ITS PHONOLOGICAL CHARACTERISTICS AND PROSODIC FEATURES. Zenodo (CERN European Organization for Nuclear Research). https://doi.org/10.5281/zenodo.7327004</span></p></div><div class="c7"><p class="c19"><a href="#cmnt_ref48" id="cmnt48">[av]</a><span class="c2">Praat: doing Phonetics by Computer. (n.d.). https://www.fon.hum.uva.nl/praat/</span></p></div></body></html>